{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision:  Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Science: COMS W 4995 006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due: March 20, 2018\n",
    "\n",
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we provide three networks for classifying handwritten digits from the MNIST dataset. The networks are implemented and tested using the Tensorflow framework. The third and final network is a convolutional neural network (CNN aka ConvNet) which achieves 99.25% accuracy on this dataset. \n",
    "\n",
    "Your task is to re-implement all three networks using the Keras wrapper around Tensorflow OR\n",
    "re-implement using Pytorch. You will likely find several Keras or Pytorch implementations on the internet. It is ok to study these. However, you must not cut and paste this code into your assignment--you must write this yourself. Furthermore, you need to comment every line of code and succintly explain what it is doing! \n",
    "\n",
    "Here is what is required:\n",
    "\n",
    "a) A FULLY commented re-implementation of the ConvNet below using the Keras wrapper on Tensorflow OR Pytorch.\n",
    "\n",
    "b) your network trained on the same MNIST data as used here.\n",
    "\n",
    "c) an evaluation of the accuracy on the MNIST test set.\n",
    "\n",
    "d) plots of 10 randomly selected digits from the test set along with the correct label and the assigned label.\n",
    "\n",
    "e) have your training record a log of the data using the Keras API and then use Tensorboard (a command line tool) to display plots of the validation loss and validation accuracy. you can zip up a screenshot of this with your notebook before submission.\n",
    "\n",
    "f) have your training continually save the best model so far (as determined by the validation loss) using the Keras API or Pytorch.\n",
    "\n",
    "g) after training, load the saved weights using the best model so far. re-run you accuracy evaluation using these saved weights.\n",
    "\n",
    "Below we include the Tensorflow examples shown in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Convolutional Neural Network in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers a python and tensorflow-based solution to the handwritten digits recognition problem. It is based on tensorflow tutorials and Yann LeCun's early work on CNN's. This toturial compares a simple softmax regressor, a multi-layer perceptron (MLP), and a simple convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the MNIST digit dataset directly from tensorflow examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import tensorflow and begin an interactive session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression Model on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create placeholders for the data. Data will be dumped here when it is batched from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what this data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dae8ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113a93fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP4QSP4T6GwsTyHDheMttAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113c36bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113ccc2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i in range(4):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first going to do softmax logistic regression. This is a linear layer followed by softmax. Note there are NO hidden layers here. Also note that the digit images (28x28 grayscale images) are reshaped into a 784 element vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the parameters (weights) for our linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use tensorflows initializer to initialize these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our linear layer as a function of the input and the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_regressor = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create our loss function. Note that the cross entropy is $ H_{\\hat{y}}(y) = -\\sum_i \\hat{y}_{i} \\, \\log(y_{i})$ where $\\hat{y}$ is the true probability distribution and is expressed as a one-hot vector, $y$ is the estimated probability distribution, and $i$ indexes elements of these two vectors. Also note that this reduces to $ H_{\\hat{y}}(y) = -\\, \\log(y_{i^*})$ where $i^*$ is the correct label. And if we sum this over all of our samples indexed by $j$, then $H_{\\hat{y}}(y) = -\\sum_j  \\log(y^{(j)}_{i^*})$. This is precisely the same loss function as we used before, but we called the MLE loss. They are one and the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_regressor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tell tf to use gradient descent with a step size of 0.5 and to minimize the cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train by grabbing mini-batches with 100 samples each and pushing these through the network to update our weights (W and b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "  batch = mnist.train.next_batch(100)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define how to compute correct predicitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_regressor,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from these correct predictions how to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9192\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out some test images and the corresponsing predictions made by the network. But first, let's add an output to the computation graph that computes the softmax probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_regressor = tf.nn.softmax(logits=y_regressor, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12772b290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  1.67203823e-03   6.03468334e-06   6.42732251e-03   1.87764294e-04\n",
      "    9.26438749e-01   4.59894276e-04   3.28759407e-03   1.33758076e-02\n",
      "    5.87336766e-03   4.22714762e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABXBJREFUeJzt3c+r5WUdwPF77sw0MFig5AhOWJGaI24UrpDYImGSskjE\noZX9AS3Ulbh0IahbUYSyXYTgToQWI6jgookZSiEkKwzSwFKy/Hln7r2nv+A8V87h3Dv3vF+v7ed8\nn+/ZvPksnvtjMp1O14Ce9f3+AsD+ED9EiR+ixA9R4oco8UOU+CFK/BAlfog6vJcvO7V+2o8TwpKd\n2Xl+8kU+Z/NDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6IO7/cXYLV9+LPvzJydffyZ4bM3Pv3z4fyaJ34/nE+3tobzOpsfosQPUeKHKPFDlPghSvwQJX6I\nmkyn0z172an103v3MvbE4RNXD+cPvHpm5uz7xy4u9O4ffPu7w/nORx8tdP5BdWbn+ckX+ZzND1Hi\nhyjxQ5T4IUr8ECV+iPIrvSzkX3d+fThf5DrvlnM/Hc6v/Pituc/G5ocs8UOU+CFK/BAlfogSP0SJ\nH6Lc8zO0fuzYcH7n/a8t7d1Hn7t8/IE9/HX0VWTzQ5T4IUr8ECV+iBI/RIkfosQPUe75Gdq87eRw\n/ujxX8199qc7F4bzr/zmd3Ofze5sfogSP0SJH6LED1HihyjxQ5T4Ico9P0Nv33NoaWff+5e7d/nE\nP5f2bmx+yBI/RIkfosQPUeKHKPFDlPghyj0/Q3dtvL7Q8//d+Wzm7OIjVw2fXXfPv1Q2P0SJH6LE\nD1HihyjxQ5T4IcpVX9zmDzeG86dO/HKh89/Zmj1bf/UPC53NYmx+iBI/RIkfosQPUeKHKPFDlPgh\nyj1/3HsbR5Z6/o9ffHDm7Lq1s0t9N2M2P0SJH6LED1HihyjxQ5T4IUr8EOWeP+5LN/9noeffvPDp\ncH7Dk+/PnG0v9GYWZfNDlPghSvwQJX6IEj9EiR+ixA9R7vlX3Oc/unU4P7fxzC4nHBpO/3zx+HC+\n/dbfdjmf/WLzQ5T4IUr8ECV+iBI/RIkfosQPUe75V9xnXx3f0x+ZjOe7eej8PcP5N9feWOh8lsfm\nhyjxQ5T4IUr8ECV+iBI/RLnqW3Gbd3+40PO7/Wnurz273H/xzfLY/BAlfogSP0SJH6LED1Hihyjx\nQ5R7/hVw6PpvzZyd2/j1bk8Pp7/9+Kbh/MhL53c5n0uVzQ9R4oco8UOU+CFK/BAlfogSP0S5518B\n731v9r/JXvRPcz/18qnh/Lq1swudz/6x+SFK/BAlfogSP0SJH6LED1Hihyj3/Cvg8ysmcz97fvPC\ncH7yiXeG862538x+s/khSvwQJX6IEj9EiR+ixA9RrvpWwPE73p372Rf+d/Nwvv3v9+c+m0ubzQ9R\n4oco8UOU+CFK/BAlfogSP0S55z8AJkePDuc/ufr1uc/+4MJlw/l0c3Pus7m02fwQJX6IEj9EiR+i\nxA9R4oco8UOUe/6DYHt7OP7Fm7fPnD1429+Hz77yj2uH8xNrfxrOObhsfogSP0SJH6LED1Hihyjx\nQ5T4Ico9/wEw3Rr/I+xvPPzJzNnJx+4bPjv545fn+k4cfDY/RIkfosQPUeKHKPFDlPghSvwQ5Z5/\nBWz/9e2Zs2tO7+EX4UCx+SFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKH\nKPFDlPghSvwQJX6IEj9EiR+ixA9Rk+l0ut/fAdgHNj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQ9X8Tl4ztsCYvaQAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11058bad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  9.20873049e-07   9.87897158e-01   2.22241855e-03   1.86755520e-03\n",
      "    3.91291178e-05   9.39880556e-05   3.30834628e-05   3.73039884e-03\n",
      "    3.64026078e-03   4.75243636e-04]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJX4IJX4IJX4IJX4I9QkUIOmQAHIDdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed9c910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  5.94127778e-06   1.63856862e-06   2.03961849e-06   2.16156419e-04\n",
      "    9.74607527e-01   5.81776584e-03   5.42712551e-05   1.18222029e-03\n",
      "    1.06608802e-02   7.45144626e-03]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkX9GlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed6d950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Class probabilities =  [[  1.32794867e-06   3.03926598e-03   1.02855719e-03   3.06596723e-03\n",
      "    1.28692212e-02   9.07216594e-03   2.42878319e-04   1.96316512e-03\n",
      "    6.66321721e-03   9.62054253e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKPFDKPFDKPFDKPFDKPFDqP8AIYYF0tDQzC4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11edb4c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  8.77247099e-03   5.61122533e-06   5.13427751e-03   1.86741403e-07\n",
      "    6.87260833e-03   3.76259210e-03   9.73673403e-01   4.59226328e-07\n",
      "    1.65836595e-03   1.20098288e-04]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print \"Label = \", label\n",
    "    print \"Class probabilities = \", y_probs_regressor.eval(feed_dict={\n",
    "        x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Multi-Layer Perceptron on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define both weight and bias variables and how they are to be initialized. Note that the weights are are distributed according to a standard normal distribution (mean = 0, std = 0.1). This random initialization helps avoid hidden units get stuck together, as units that start with the same value will be updated identically in the non-convolutional layers. In contrast, the bias variables are set to a small positive number--this is help prevent hidden units from starting out and getting stuck in the zero part of the ReLU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create placeholders for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the first and only fully connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_h = weight_variable([784, 512])\n",
    "b_h = bias_variable([512])\n",
    "h = tf.nn.relu(tf.matmul(x, W_h) + b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_out = weight_variable([512, 10])\n",
    "b_out = bias_variable([10])\n",
    "y_MLP = tf.matmul(h, W_out) + b_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again use cross entropy loss on a softmax distribution on the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we choose an Adam learning rate and update rule. We then run this for 20,000 iterations and evaluate our accuracy after training. Note this softmax MLP network does quite a bit bettter than our softmax regressor. The non-linear layer really helps makes sense of the data! But we can do better still..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.2\n",
      "step 1000, training accuracy 0.9\n",
      "step 2000, training accuracy 0.9\n",
      "step 3000, training accuracy 0.98\n",
      "step 4000, training accuracy 0.98\n",
      "step 5000, training accuracy 0.94\n",
      "step 6000, training accuracy 0.96\n",
      "step 7000, training accuracy 1\n",
      "step 8000, training accuracy 0.96\n",
      "step 9000, training accuracy 1\n",
      "step 10000, training accuracy 0.98\n",
      "step 11000, training accuracy 1\n",
      "step 12000, training accuracy 0.94\n",
      "step 13000, training accuracy 0.98\n",
      "step 14000, training accuracy 1\n",
      "step 15000, training accuracy 0.96\n",
      "step 16000, training accuracy 0.96\n",
      "step 17000, training accuracy 0.98\n",
      "step 18000, training accuracy 1\n",
      "step 19000, training accuracy 0.96\n",
      "test accuracy 0.9779\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_MLP,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%1000 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1]})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Convolutional Neural Network: LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make our first CNN. It's quite simple network, but it's surprisingly good at this handwritten digit recognition task. This a variant on Yann LeCun's CNN network that really helped to move deep learning forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define both weight and bias variables and how they are to be initialized. Note that the weights are are distributed according to a standard normal distribution (mean = 0, std = 0.1). This random initialization helps avoid hidden units get stuck together, as units that start with the same value will be updated identically in the non-convolutional layers. In contrast, the bias variables are set to a small positive number--this is help prevent hidden units from starting out and getting stuck in the zero part of the ReLu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define how the convolution is to be computed and the extent and type of pooling. The convolution will use a 5x5 kernel and will pad the image with zeros around the edges and use a stride of 1 pixel so that the resulting image (after convolution) has the same size as the original input image. The network will learn the weights for a stack of 32 separate kernels along with 32 bias variables. Finally, after the ReLu is performed the result will be under go 2x2 max pooling, thus halfing both dimensions of the image. The choices for the stride, padding, and pooling are not parameters that the network needs to estimate. Rather these are termed \"hyperparamters\" that are usually set by the network designer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the weight and bias variables for the first convolutional layer as described above. Note the output has depth 32, so there will be 32 feature images after this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike for our softmax regressor above, here we need keep the images as images and not collapse these into vectors; this allows us to perform the 2D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define are first layer of our CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And wasting no time, we define are second layer. The second layer will have to process 32 feature images coming out of the first layer. Note that the images input to this layer have $\\frac{1}{4}$ the number of pixels as the original input images due to the 2x2 pooling in the previous layer. Note that convolution layer NOT fully connected as our previous hidden layers have been. A unit in the output layer has a limited \"receptive field.\" Its connections to the input layer are spatially limited by the kernel (or filter) size. Also, because of weight sharing in convolutional layers, the number of parameters for a convolutional is the size of the kernel x the depth of the input layer x depth of the output layer + depth of the output layer. So for the second layer of our ConvNet, we have 5 x 5 x 32 x 64 + 64 = 51,264 parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pooling stage of our second convolutional layer, we have 64 7x7 \"feature\" images. In one penultimate fully connected hidden layer, we are going to map these feature imges to a 1024 dimensional feature space. Note we need to flatten these feature images to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is added here, although it is not really needed for such small network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a final linear output layer mapping features to scores topped off with a softmax cross entropy loss function, as explained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we choose an Adam learning rate and update rule. We then run this for 20,000 iterations and evaluate our accuracy after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.16\n",
      "step 1000, training accuracy 0.94\n",
      "step 2000, training accuracy 1\n",
      "step 3000, training accuracy 0.98\n",
      "step 4000, training accuracy 1\n",
      "step 5000, training accuracy 0.96\n",
      "step 6000, training accuracy 0.98\n",
      "step 7000, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 9000, training accuracy 0.98\n",
      "step 10000, training accuracy 1\n",
      "step 11000, training accuracy 1\n",
      "step 12000, training accuracy 1\n",
      "step 13000, training accuracy 1\n",
      "step 14000, training accuracy 1\n",
      "step 15000, training accuracy 1\n",
      "step 16000, training accuracy 1\n",
      "step 17000, training accuracy 1\n",
      "step 18000, training accuracy 1\n",
      "step 19000, training accuracy 1\n",
      "test accuracy 0.9925\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%1000 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an output to compuational graph that computes the label probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_probs = tf.nn.softmax(logits=y_conv, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9925\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we step through some test examples and see how well the network is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4odQ4odQ/wPLax9UR54iwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d599f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Class probabilities =  [[  5.28820287e-14   1.61565119e-12   1.47112888e-12   1.99402633e-10\n",
      "    8.20477112e-07   1.07506337e-09   4.57562201e-15   8.61227306e-07\n",
      "    3.80472631e-09   9.99998331e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx7nqBBMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ec3dcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  1.00000000e+00   3.50560683e-12   1.00434594e-09   1.73949210e-14\n",
      "    8.60713218e-16   3.75027960e-12   9.13440157e-11   2.25712261e-11\n",
      "    1.23941948e-12   4.15561162e-11]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAB6xJREFUeJzt3V+s13Udx/Hf7xwPEjB0LkArSDqgqIUzRs7FTmNlxWqp\nbXqDWs3WhW1IznXjZt205lYpiNlYUTeVzuzPsg1kpJuoiKNSg5QBpi3K0jKY8Uc4v6660u/7h+cc\nzvlxXo/H7Yvv7/vd9Mn34sM5v3an02kBefom+gGAiSF+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CHXa\neN7s8r6r/XNCOMk2D9/fPpE/580PocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPocQP\nocQPocQPocQPocQPocQPocQPocQPocQPocQPocb1V3czMn3TppX7kscPNm5fm/WH8tqP7/psuU+5\n/MVy59TlzQ+hxA+hxA+hxA+hxA+hxA+hxA+hnPP3gG7n+LvXn1/uv5y1vnEb7nLvvzx9TrkPtpzz\nT1be/BBK/BBK/BBK/BBK/BBK/BBK/BDKOX8P2HfrxeW+a/nacl+5b0Xj9uo35pfXDm7cVu5MXt78\nEEr8EEr8EEr8EEr8EEr8EEr8EMo5fw84OvvYqK5/5tGFjdv8jU+M6rOZvLz5IZT4IZT4IZT4IZT4\nIZT4IZSjvh4wMONouR8crvd5m4+M5eMQwpsfQokfQokfQokfQokfQokfQokfQjnnHwf9C+pfn71z\naEO537T/o/XnP/y7t/1M4M0PocQPocQPocQPocQPocQPocQPoZzzj4Pnv37mRD/CKenIiqXlfnDu\nyP/3nbXjQLl3duwc8WefKrz5IZT4IZT4IZT4IZT4IZT4IZT4IZRz/nFwx6X3jer6x37ywXI/u/X4\nqD7/ZNr740satzWX/rS89gNTtpb7nP7TR/RMrVarteeN+mvRr/jZV8p98JZtI753r/Dmh1Dih1Di\nh1Dih1Dih1Dih1Dih1DO+cdA/8yZ5T6970i5P3RoermffcfJO8dvD0wp96PLF5f7rff8sNyHpu5o\n3Aba/eW124/U5/jXP3d1ud88/6HG7TPT/1te+90rf1Dud264qtyP79pd7r3Amx9CiR9CiR9CiR9C\niR9CiR9COeobAy+sfn+5L5u6pdwvfPj6cl/Q+v3bfqb/6/b14M9/eU6577rmrhHfu9VqtbYcmtG4\n3bjp8+W1i9a8Uu6n795b7ne3zmvc7toyt7z2wUU/L/dvzjuj3KfsKuee4M0PocQPocQPocQPocQP\nocQPocQPoZzzj4H24vrrnrsZ2PuOMXqSN+v29eDPLb+73Ie7fP7KfSvK/cBX3924LXziyfLa413u\nPRp79p1d/4FFJ/HmPcKbH0KJH0KJH0KJH0KJH0KJH0KJH0I55x8Di2a/PKH3by+5qHH7xbJ7ulw9\nUK4XPfKlcl94w5/KvX346S737023/WNpuU995Nly7/bvI3qBNz+EEj+EEj+EEj+EEj+EEj+EEj+E\ncs4/Bt4z7bVy7+v2d2y7M6r7717V/FXWFwzU5/hLnrq23AdX1t8ZcCqcZ7+VgRlHy/31Y/XXgw8f\nPjyWjzMhvPkhlPghlPghlPghlPghlPghlPghlHP+MTDcqf8OHe52Gt5pj+r+58xp/ncG3e594az6\ndxH8e0RP1Bv6F8xv3HYObSivHXrmmnKf2do7omfqJd78EEr8EEr8EEr8EEr8EEr8EMpR3yRw5g3N\nP1765KP1j/Sum/frcr/s9lvK/by1L5b7sb/uL/eT6YL7mp/t5eOHymunrjmry6c76gNOUeKHUOKH\nUOKHUOKHUOKHUOKHUM75T1D146FDZ/x2HJ/kzaqz9Ns/dmV57cUP7Cv3P167ttxv/Mjycv/bp5rP\ny4+/+q/y2teuu6zcl61+stxvm/NY47bk3vrfLwxu3Fbuk4E3P4QSP4QSP4QSP4QSP4QSP4QSP4Ry\nzn+Cju95oXG79+8fKq+9anBjub932Uvl3j9zZrkfP3CgcTu278/ltTsuqf/+H7puVbmf9Uz99eTt\nd77RuL2wbm557c6hdeXe7Wfyq7P8wVsm/zl+N978EEr8EEr8EEr8EEr8EEr8EEr8EMo5/xg4/MX6\nHP47Dywq9wcX/arcb9ry4XLf/r3mn3ufsf9YeW03/1xaf8X30lX17wP49ru2Nm59Xd496/9zbrn/\n6FufLvfBDU+UezpvfgglfgglfgglfgglfgglfgjV7nQ643azy/uuHr+b9ZDT3nduuV/xm+3l/rmZ\n9ddgj0a347bhVn3UNxqLt95Q7gtufqXcJ/Lrv3vZ5uH72yfy57z5IZT4IZT4IZT4IZT4IZT4IZT4\nIZRz/h7QP2d2ub/0hQXl/vr85l+PvemTd5bXfmLT6nJvjfK/2PnfP9z80U89O7oP5y055wdK4odQ\n4odQ4odQ4odQ4odQ4odQzvlhknHOD5TED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HE\nD6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HE\nD6HED6HED6HED6HED6HED6HED6HanU5nop8BmADe/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BBK\n/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BDqfwgqIydQmb5WAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1274c8090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "Class probabilities =  [[  1.41643053e-09   7.71405238e-14   1.62943230e-15   5.57100261e-15\n",
      "    2.53674198e-13   1.26207560e-11   1.00000000e+00   4.33625261e-15\n",
      "    3.95802037e-11   7.02078399e-16]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhqECvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1277466d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Class probabilities =  [[  3.76756785e-12   1.12312442e-11   3.20851019e-11   2.01345451e-09\n",
      "    2.59802891e-05   6.02736749e-09   2.61297559e-12   4.99466495e-08\n",
      "    6.30753760e-09   9.99974012e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12778c250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  1.00000000e+00   1.98105139e-12   1.07032493e-12   2.90848210e-14\n",
      "    8.34232247e-15   6.83068185e-12   1.36369707e-08   4.16134821e-10\n",
      "    5.86183532e-12   1.50796278e-10]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print \"Label = \", label\n",
    "    print \"Class probabilities = \", y_probs.eval(feed_dict={\n",
    "        x: batch[0], y_: batch[1], keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "rows = cols = 28\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(callback, names, logs, batch_no):\n",
    "    for name, value in zip(names, logs):\n",
    "        summary = tf.Summary()\n",
    "        summary_value = summary.value.add()\n",
    "        summary_value.simple_value = value\n",
    "        summary_value.tag = name\n",
    "        callback.writer.add_summary(summary, batch_no)\n",
    "        callback.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mnist.train.images.reshape(-1, rows, cols, 1)\n",
    "train_labels = mnist.train.labels\n",
    "val_data = mnist.validation.images.reshape(-1, rows, cols, 1)\n",
    "val_labels = mnist.validation.labels\n",
    "test_data = mnist.test.images.reshape(-1, rows, cols, 1)\n",
    "test_labels = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Keras Implementation) Softmax Regression Model on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/18\n",
      "54700/55000 [============================>.] - ETA: 0s - loss: 0.4006 - acc: 0.8854Epoch 00000: val_loss improved from inf to 0.29838, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.3998 - acc: 0.8856 - val_loss: 0.2984 - val_acc: 0.9174\n",
      "Epoch 2/18\n",
      "53600/55000 [============================>.] - ETA: 0s - loss: 0.3103 - acc: 0.9130Epoch 00001: val_loss improved from 0.29838 to 0.28004, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.3098 - acc: 0.9128 - val_loss: 0.2800 - val_acc: 0.9274\n",
      "Epoch 3/18\n",
      "53700/55000 [============================>.] - ETA: 0s - loss: 0.2953 - acc: 0.9165Epoch 00002: val_loss improved from 0.28004 to 0.27611, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.2946 - acc: 0.9165 - val_loss: 0.2761 - val_acc: 0.9226\n",
      "Epoch 4/18\n",
      "53800/55000 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.9195Epoch 00003: val_loss improved from 0.27611 to 0.27433, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.2875 - acc: 0.9190 - val_loss: 0.2743 - val_acc: 0.9270\n",
      "Epoch 5/18\n",
      "53500/55000 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9216Epoch 00004: val_loss improved from 0.27433 to 0.26833, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.2819 - acc: 0.9212 - val_loss: 0.2683 - val_acc: 0.9250\n",
      "Epoch 6/18\n",
      "54200/55000 [============================>.] - ETA: 0s - loss: 0.2775 - acc: 0.9224Epoch 00005: val_loss improved from 0.26833 to 0.26711, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.2766 - acc: 0.9225 - val_loss: 0.2671 - val_acc: 0.9244\n",
      "Epoch 7/18\n",
      "54100/55000 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.9238Epoch 00006: val_loss improved from 0.26711 to 0.26665, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.2742 - acc: 0.9237 - val_loss: 0.2666 - val_acc: 0.9272\n",
      "Epoch 8/18\n",
      "54600/55000 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9243Epoch 00007: val_loss did not improve\n",
      "55000/55000 [==============================] - 2s - loss: 0.2713 - acc: 0.9241 - val_loss: 0.2698 - val_acc: 0.9256\n",
      "Epoch 9/18\n",
      "53900/55000 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.9247Epoch 00008: val_loss did not improve\n",
      "55000/55000 [==============================] - 2s - loss: 0.2689 - acc: 0.9248 - val_loss: 0.2689 - val_acc: 0.9258\n",
      "Epoch 10/18\n",
      "54600/55000 [============================>.] - ETA: 0s - loss: 0.2669 - acc: 0.9257Epoch 00009: val_loss did not improve\n",
      "55000/55000 [==============================] - 2s - loss: 0.2671 - acc: 0.9256 - val_loss: 0.2691 - val_acc: 0.9258\n",
      "Epoch 11/18\n",
      "54500/55000 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.9259Epoch 00010: val_loss did not improve\n",
      "55000/55000 [==============================] - 2s - loss: 0.2651 - acc: 0.9259 - val_loss: 0.2684 - val_acc: 0.9254\n",
      "Epoch 12/18\n",
      "54700/55000 [============================>.] - ETA: 0s - loss: 0.2639 - acc: 0.9269Epoch 00011: val_loss improved from 0.26665 to 0.26406, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.2636 - acc: 0.9269 - val_loss: 0.2641 - val_acc: 0.9256\n",
      "Epoch 13/18\n",
      "53800/55000 [============================>.] - ETA: 0s - loss: 0.2621 - acc: 0.9268Epoch 00012: val_loss did not improve\n",
      "55000/55000 [==============================] - 1s - loss: 0.2629 - acc: 0.9267 - val_loss: 0.2669 - val_acc: 0.9272\n",
      "Epoch 14/18\n",
      "54300/55000 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.9264Epoch 00013: val_loss improved from 0.26406 to 0.25939, saving model to saved_models/softmax_regr_model.h5\n",
      "55000/55000 [==============================] - 2s - loss: 0.2613 - acc: 0.9267 - val_loss: 0.2594 - val_acc: 0.9290\n",
      "Epoch 15/18\n",
      "53600/55000 [============================>.] - ETA: 0s - loss: 0.2606 - acc: 0.9280Epoch 00014: val_loss did not improve\n",
      "55000/55000 [==============================] - 2s - loss: 0.2601 - acc: 0.9281 - val_loss: 0.2724 - val_acc: 0.9254\n",
      "Epoch 16/18\n",
      "54900/55000 [============================>.] - ETA: 0s - loss: 0.2599 - acc: 0.9282Epoch 00015: val_loss did not improve\n",
      "55000/55000 [==============================] - 1s - loss: 0.2598 - acc: 0.9282 - val_loss: 0.2635 - val_acc: 0.9280\n",
      "Epoch 17/18\n",
      "54900/55000 [============================>.] - ETA: 0s - loss: 0.2589 - acc: 0.9274Epoch 00016: val_loss did not improve\n",
      "55000/55000 [==============================] - 2s - loss: 0.2588 - acc: 0.9274 - val_loss: 0.2649 - val_acc: 0.9308\n",
      "Epoch 18/18\n",
      "54600/55000 [============================>.] - ETA: 0s - loss: 0.2586 - acc: 0.9278Epoch 00017: val_loss did not improve\n",
      "55000/55000 [==============================] - 2s - loss: 0.2579 - acc: 0.9280 - val_loss: 0.2654 - val_acc: 0.9282\n",
      " 9440/10000 [===========================>..] - ETA: 0sTest loss: 0.271363408004\n",
      "Test accuracy: 0.9262\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"saved_models/\"\n",
    "model_name = \"softmax_regr\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "modelpath = os.path.join(save_dir, model_name + \"_model.h5\")\n",
    "weightpath = os.path.join(save_dir, model_name + \"_weight.h5\")\n",
    "\n",
    "# Network parameters for learning rate, batch size,\n",
    "# number of epochs\n",
    "lr = 0.5\n",
    "batch_size = 100\n",
    "epochs = 18\n",
    "\n",
    "# Define expected input shape\n",
    "input_shape = (rows, cols, channels)\n",
    "inputs = Input(shape = input_shape)\n",
    "\n",
    "# Flatten input to a vector\n",
    "x = Flatten()(inputs)\n",
    "\n",
    "# Fully connected layer with units = 10\n",
    "# equivalent to the number of classes\n",
    "# Apply softmax activation to all\n",
    "outputs = Dense(10, activation = 'softmax', \n",
    "                kernel_initializer = 'zeros')(x)\n",
    "\n",
    "# Define mode\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "# Specify categorical crossentropy loss with\n",
    "# Stochastic gradient descent (learning rate = 0.5)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = SGD(lr = 0.5),\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Callback to save logs for tensorboard\n",
    "tensorboard = TensorBoard(log_dir = './logs', batch_size = batch_size)\n",
    "\n",
    "# Callback to save the best model\n",
    "checkpoint = ModelCheckpoint(filepath = modelpath,\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True)\n",
    "\n",
    "callbacks = [tensorboard, checkpoint]\n",
    "\n",
    "# Fit training data with batch size of 100\n",
    "# Save model based on validation loss\n",
    "model.fit(train_data, train_labels,\n",
    "          batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (val_data, val_labels),\n",
    "          shuffle = True, callbacks = callbacks)\n",
    "\n",
    "# Evaluate Test data\n",
    "score = model.evaluate(test_data, test_labels, verbose = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAJYCAYAAAB4hltMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xe8HFX5x/HvQxICgVBCCZ0oIiAo\nIEWwYCgiIAKRIvwUiDQbCigYQMGgKBaUJoLU0KRYkIhIkSotUhQNTVGCdEhISAAJhDy/P85Z7mTn\n7N7du3vn7s79vF+vfd27z5w5c3b22d05U86YuwsAAAAAgKIsNNANAAAAAAAMLnREAQAAAACFoiMK\nAAAAACgUHVEAAAAAQKHoiAIAAAAACkVHFAAAAABQKDqiAAYlMxtrZm5mpb6HVeU1mtnYgW5LX5jZ\nxNj+W+qU+ZyZ3WVmszOv99A4bVJ8PqmoNmfa1VU5ZmbjY3unDXRbuoWZfcTM/mBmL5rZW3H9/W6g\n2wUA3WDoQDcA6ARmNkLSRyVtJOn98e9qcfJx7j6xwXpGS/qGpB3j/P+T9KCkCySd69y4F2grM/u6\npBPj03mSXpDkkl4dsEZhUDCzzSTdpLAt5ZJmSHpL0sw4fayksZKmufukAWkkAHQwOqJAsKmka1qp\nwMw2knSdpGVi6BVJIyV9OD52M7Od3P2NVpYDDDLTJT0q6b81ph8R/54q6XB3f7Nq+rNx/mf7p3ml\n8rLCunp6oBvSJQ5V2I66Q9JO7v5S1fSxkr4t6VZJkwptGQB0AU7NBXrMlHSjpB9L2kvSc43OaGZL\nSrpaoRP6iKRN3H2kpMUkHSzpTUkfl3Rym9sMlJq7/8zd13b3faqnmdlykkbHp2cnOqFy96Pi/Ef1\nd1u7nbtfGdfV1gPdli7x3vj3skQnFADQC46IAsGf3X1UNmBmP2hi/sMlraBwKu4O7v64JMWjn6eb\n2RKSvi/pIDM72d3/2aZ2A4PZiMz/rwxYKzBYVfKP3AOAPuCIKCDJ3d9qsYrK0ZrLKp3QKqcpbKwM\nkfSZvi7EzD5kZheb2RNm9rqZvWxmfzGzCWa2eKL8pzODt4yrUecGsS43s29WTVvBzL5iZleZ2cNx\nef8zs8fM7BwzW7dOWxcYJCYOhHJXrGOmmf3JzLbIlB8al3VfHHTmZTO7xszeX6P+BQaCMbONzezX\nZvZsfD2PmdmPzWyphlZuehkLm9mXzOxmM5tuZm+Y2XNxfWxfZ75Fzezw+HpnmtmbcTCTh8zsAjPb\ntYU2rWNmp8e65pjZK2b2qJldZma7mlnD3+tmtl4cDOgmM/t3fG9nm9lfzex4M1u2zrxDzewgM7sl\nrps3zWxGbMvlZrZ/jfk+bWZ/NLPn4zyzzOxfZjbZzL5sZotUlc8NVlR57yVNyxR9PJPr0zJlex2s\nyMzGmNnJZvZgXJ+vmdkjZnaKma1Wa74479pmdknMi9fN7D9mdpqF68X7rMF21x1cyMw+bma/NbOn\nYu7Oju27PuZn9c63mvVVvw9mtrX1DNLzuoXvh29Xv3+JenaO+TYrrusHzOwbZjYs9V43o9ncysy3\noZldaD3fqzPN7E4zO9TMhifKV753xsTQ+Znc85hPrnBariR9tGq6m9n4TH23xNjE+Lk6LH4GXzGz\nF8zsd2a2fqb8CDP7lplNNbNX4+fucjNbo8brWyi+X6ea2d2ZfJhhZrea2RfMbFhivuGxHW5m96TK\nxHKXxzLPWJ3vjEaY2bTK+jGzxc3sO2b2DwvfdW5mY6rKjzSzIy18175kZnPN7EkL34eb97KsZc3s\npPiZeN3Cb8evLP7mZN6rsVXzVf/2bGjhO+CpmHe3tLIOgEHF3Xnw4JF4KGzkuqSJvZRbK5ZzSbvX\nKXdNLHNXH9qykKRTMstxSXMUBmepPH9E0uqJec9Vz0Aaq1ZNWyzO5wqDbixUNX1Spv43Yx1vZmKv\nS9q1Rpsr807K/P+mpNlVde4oabjC9bUuaa5Cp71S5lVJGyXqH5sps3OczxWuc5ubmTZN0ph689do\n/+qSpmbqmS9pVtV7cEZivpGS/lY138yq9Tatjzk5QWEwlEo9/1PPACmV2FJV81TiY+vkeLau+ZnY\nU5LWSsw3RNL1VetiVsyHt2OJ+c6rmmdOfH+zsTFV80yM8VsysQ8qnDr/Yma+F2PsOUn3pPKwxjr9\nTFW7X5f0Wub5bEnb1ph3u6p558T16JKekfS5ejnWy3tdt92xzPha+STp2Kr1+mpsXzY2ton63n4f\nFK7Lna+e3M7mzE2ShtRo74lVy89+Lm6V9L3q97qJ9dV0bsX5Dqtq/yxJb2SePyBpxap5KnlW+dy9\nnIk9J2nV+LfyPfZG1fTnJH06U98tsdz3JP1J6e/BOZI2Vrj84371fGazufq8pNUSr3FMYt1Uf5fd\nJmnRxLxrZ9bjjxPTD4jT3pK0dV++12p8J31d4XrlyrqYWf0eStpA0pOZ1zBPC/6+zJd0VI3lvFvh\nWujs5/7lzPI+mZlW/TkZm5m2ayZfXo7vSdP5y4PHYH0MeAN48OjUhxrviO6a+VFap065H1V+rPrQ\nlu9mNjS+JGlUjA+LP4qVDZP7lO9MLibpYfVs7A3JTKtsvE2XtHJiud9SOO14PUlDY2whSetKujjO\n+4qklRLzTlLPxuZrkg6qbOgodN7vjdMfVzhiPEPS7vE1mcLIxY/FMrcn6s9uDMySdHNl/StcdrCH\npJfi9L+oauNYdTqiVevsZoURlYfHaUsqbLxWNuoPSawzj6/nU5n5FpK0kqS9JZ3Vhxz4Yub1XiVp\ng8y0EZI+JukySUtUzZfcmIrTLpC0rzIbr5IWlrS1pCmVnErM91n1bAjvL2nxGDdJy0saJ+lXVfN8\nWD0brN9QzOE4bRlJ28acWalqvomq0TnRghvYY2qst0oeTkpM+1hsz5uSfhjrs/hYS9IV6tnAXK1q\n3lXUs+H6gKRNM+/zdgobyJWN51yONfB+12x3psx4JTqOCjtRKp2kn2TXaczfD0s6XVU7eGrVV/U+\nzIx1f1/SsnHaEpKOy7wX+yXm3zMz/RLF7xtJi0g6MOZS5fOae697WVd9za0dM236naR3ZD4De6un\nU3OHEp1r9fxGjK/Rrpq5W1Xulsy6nS5pN/V8D24i6d+ZdvxW4Ttz25hrCyl8XiujRV+cqH8Vhe/r\nT1atm8Xje17pkP20Rvv2U0/HbttMPNtJPaHZHK+xrMo6naMwwNgukoZlXseI+P+KCr+HLuk3Cr8X\nlXLLS/qOenZy7FK1jGGS/h6nvajwfTUk85puzORi7rtTC/72zJH0B0lrZ6av2Y51wYPHYHgMeAN4\n8OjUhxrviH4l86O0RJ1yh2TKLd5EO8Yo7Ol9TdL6NcqMVM+e4V0S09dXz5Gbb8dYdsNwpz6uo6vj\n/N9KTJuUqf8zielrZKa7pA8nymyVmb5K1bTsxsCjSu/N3yZTZvda8yfmOyZOu6WycZMoMy6zITM0\nE68c+U7uie/jel5aPRvFl0qyJuZNbkw1MN/iCkducu+NpJ/H+C+aqO8bcZ7rmmzHxMp7UeOz0aeO\nqMIG/D/jtIPqLP+qWObkGutguqTlE/Otp8yRtT6858l2V5UZr3RHdI/K56LJZSbrq3ofan4nKnQI\nXNINVXGT9K847fpU/maW3ZeOaF9z66E4321KdzSzR8V2S0yfpvZ2RBv5HnxN0rsSZfbLTE9+Z9VZ\n/sbq2am4SI0yl8Yyzyl09Iar58yPKc0us05bKut0nqQN65SrnOlzSZ0yh8Uyf6uKV3akzZf0kcR8\ni6hnR2RvHdEpqdzhwYNHYw+uEQVaNzLz/2t1ymWnjaxZKm+8wqmQ17r7A6kC7j5HYY++FEbnrZ7+\ngHpuc3GMme0t6cz4/HR3n9xEe7L+EP9+uE6Z/0r6ZaJN/1Y44imFwaJuT8x7q8JpUpL0vjrL+LG7\n/y+xjD9JujM+3bPO/NUq1zf+1BMjsUa/U+gcLquwN75iVvy7YhPL681uCjnzpqSvubu3se4kd39F\nYf1L+fe38hpXaKLKyjzLmdmQVtrWJltIWlOhI3lOnXIXxr9vf67MzCR9Oj49091fqJ7J3adK+nV7\nmtq0yroeaWaLtbnuueq5b2u1q+Lf6s/qBpLeFf//fo38vUC1b9HTm6Zzy8zeJ2md+PR4T4wT4O6/\nVzibQgojqfe32xv4Hvy1uz+WKHNd/LuoQl43zN3vVTiiupjCe5XyBYUjsaMV3qsTFXZwzpG0V53v\nyb661t3/mpoQr/X9v/j0h3XqqHx217cFr9nePf69zd3/XD2Tu7+uMHp+I36cyh0AjWHUXKDzfSj+\n3dbM6t1SpjJY0eqpie5+mpl9TGEvf+UH+h8Kp97WFAfJ+LxCZ2RMXI5VFVulThX31uk4Pa+wgXpP\njTa/ZWbTJa2scFSwlpt6mfZBhb3+vTKzldWzDs81s3obGdl1PiX+f7XCRuvBFm4vcrnCBub0RpZf\nwwfj3/vcva33wzSzHRVOQ9xEYSNzRKJY9ft7jaQjJe1kZn9UyKdb3f2ZOou6UeGo/IaS/mxm50q6\nydODexWh8rlaUtIzoW+ZtHD8m/1cvUNSZaCf3nKviA5Mtb8odLBXlDTFzM5UuPbw0TbsxHgw7qRI\nqbz/o6rilQHH3lTPjqEFuLub2a0KudisvuRW5ftgnnp2uKTcoHCf6Ya+P1r0l1Sw6nsw+V2p8F1a\nkfuuNLOFFY6afkrhaP0y6sntrOR3ubu/bGZ7Sbpd4dTzii+6+39qtKkVd9SZtpHCUUtJur7OZzdr\ndfWso0o+1nvfb2mkUtVvJ4Be0BEFWjcn8/8IhaNkKdkN/Dk1yqSsFP8uFh+9SXUkKvZTOIV3EYXr\nqfaKe3+TzOxghUGSKmdPuHoGA5LC3vclemlXvdc6r4kyyREbo6cbmLZ8nTJZK2X+b3QEyLfXubv/\n0sw2VThle8/4kJk9pnBa4nnufl+D9VZUjjw+0eR8NVkYXfdiLdhRmqdwndob8fmSCrmywPvr7reb\n2QRJxytslG4X63xKocNzobvfXDXPv83sAIUj8ZvHh8zsRYXrcH8paXIRR3ujyvs8TD33Iq1n0cz/\n2Vyql3tPNduodnD3WbHT8EuF67lPi5NeNrPbFK59vbyPR7Ea+axWb1ssF//O8HBLq1rqrcua+phb\nlfdwurvPVW2V97DR749W9Pm70t3nZTpkC3xXmtnyCp/L92bCryvsrKjsaFtO4Xu+5ne5u08xs1MU\nBhKSQg5dUqfNrcidZZCR/Y5udHTq7O9iJR/r7ThrNBfrtRNALzg1F2hd9sds5TrlKtNm1zmikFI5\n1eyH7m4NPMbWqWsf9exJHqI6p9Sa2TqSTlb4nviVwlGBRdx9aXdfwd1XkPS1SvEmXk+ny57at06D\n63xStgJ3P1RhsJujJf1R4dTBdykMNHWvmZ3cZJv6o3O2v0In9C2FgT3WVBhYaVTm/a2cWpp7f939\nxwpHBg9TOE35BYWjKeMl3RRvgzCsap5LFI5MfEHhSPGTChuFe8Q6brVwz90iVN7nKQ2+x12V4/G0\n9HcofOYvULhGc0mFMyIukvTXePS/0Gb1W8WdlVud5iSFTugMhZ2RK7r7ou6+XOazXvkdq5nnFm6F\ntXsm9H5L3DasTeqdiZL9jl60wc/vLYl6Ws5HTssFWkNHFGjd1Mz/69UpV5n2UJP1V07HTZ5y26h4\nb7QT4tO/x78nxQ5nym4KP/gPS9rT3e9JHM1o5hrB/tTIDoBG91xnT3/u8zp398fc/QR330HhNLjN\n1XMd7yFmtlMT1bUlB6pUrpk9x92/Hds7v6pM3ffX3Z9x95PdfZy7j1a4NrByveVuCiP9Vs/zkrv/\nwt33dPfVFDroP1DYKPyIwgAvRWhlnWZzqZHc64vKEbB69+Vcsl4F7v6qu1/k7uPd/d0KOwomKBwN\nyx4p7W8vxr/LxlNEa2mpY9xkblXew2Utca/QjMqpql155CvuDPpUfHqwu5/v7s9VlRmixs7+OFvS\nagpHC2co7Lz6WRub26hWv6Mr+bhSnTJF76QBBiU6okDr/qmeQTa2SxWIA4Z8JD69vsn6K9egbGO9\n3Cy+lrj8SxWuCbpR4ejmXxRON7ysxobYqvHvA4kOSsU2fWlPP9iygWn3NlKRu09Tz2lZn2yhTdk6\n57v73Qqds0qufKyJKirX1W1sZu0aBKny/tYaEGRxSR9opkJ3/4e7H6ienO31Nbr7v939KPUMaNXM\nemlFpY0rmFmz1/89rnB7B6l+7m3VdKt6zIx/V61Tptn352l3/5HCLV2k4tb1/fHvMPVc77yAOADU\nFu1caC+5Vfk+GKpwe6ZaKt9xta7NrKfyvTmQR9OXU8/OjORnXeHMmLq/LWZ2oML313yF63grA7rt\nG08DL9I96rl8oC/f0ZV8HFunTL1pANqEjijQonjdUWXwnz3NbEyi2JcVBrZ5S+Eees04T+HoyLIK\n9+qrycwWrnGq1M8UbuA9Q9I+8Zqo/1O43uh9So+C+XL8+15LjAZhZturc36sD0910s1sS/UMSnN5\nE/WdHf/ub2Yb1itoZqOqntc8uhJP46psQNXq3Kf8SuHa46EKR7HbsWFbeX/XrzH9GNUY3bmXI0hS\nuCeklHmNfZmnn92snlGbT+rlSN0C73P8zF8Rn37BzHJHk8zsPQob7n1VGSF7EzPLdUbjmQyfqo7H\naZ22rv+mnnV9ZI38/az6eMS/L6/X3f+unrNTvpUabdfMdlBPZ//SPjStMl7AUn2Yt10qt32SEp91\nMxsq6Xv1KshcpiGFS0RudverFG5hJElnmtk72tTeXrn7q+rZuTDBzFarV776O1o9lxxsYWYfSpQf\nrl4G8QPQHnREgcjMljazZSsP9Xw+RmTjNTp6JyqcLjRC0h/MbKNY58Jm9kVJ343lznL3fzbTLg+3\nOanM/w0zu9DM3j4F2MyGmtkGZnaswsbeAsPvm9meCtftSeFG889k6v1SjB8cR0/Nujb+XVfS6ZUf\nczNbzMw+r/BjPqOZ19KPVlRY72tJb6+T3dSzwXG/wo3gG/UThRGFF5F0s5kdbGbLVCaa2VJmtr2Z\nXSipevj/KWZ2qpmNtcytM8xsJTM7TT23sbim0ca4+8sK90qUwm1DrjSzt99nMxthZp8ws6uauA6u\n8v4eaGYHVTpiZraCmZ0Ul1fr/f2dmZ0X18HbG9lmNsrMviVp6xj6Q2aen5nZFWa2axw8pTLP4mb2\nBYVrGavn6TfuPk/hesJ5CkeEbjOzrbPXtZrZO83sC2Z2j3o+KxUnKOzIWVbSDZWjqhZsq3BtcL3b\nOfXm9wr3dRwm6YpMbg8zs50VBp95tca8E8zsj2a2t5m9PQqqmQ03sz3Ucyunota1S/p2fPpxSReY\n2UqxTYuY2f6SfqGeo8DN6mtuTYh/PyLp15XOVFzHn1FP5/NO9ZxW34zKZRvrmlnySHB/i+MRVI7+\n/9TMtrIwUJni78g1CiMCJ3MpdsouVfhtmyLp2Mzkryu8xiUk/TJ2aotytMJ1rctKuivm+ts7zsxs\nuZgPVyq/E+FySQ8qHKn+rZntXNkRET9nV6tzLjsBys074GamPHh0wkM9N9Lu7TGpxvwbKYxCWCk3\nW5kb2ivc5214H9tmCgPKzM/U91pc3ryq9n0oM98YhYFyXNLPatR9YZz+osIgFtlpl1bVPTOzvHsl\nHRz/n5aod1K99RXL3BLLTGzgfRlfFR+badfOmXU9S+EauMq0JyS9I1Hv2/PXWO5Kku7K1DM/vv6X\nq9bJv+rkUWWeV6rm+Wkf8+AohaPq2RyYURVbqmqeWjdlX0oL3rT9rdjWSo6dWes9zLxvlcfLifXy\nK0kLJfKh8pgTl5eN/VnSYlXLmhin3ZJYH2My846psc7q5qGkXdRz1MhjHk2vyiGX9M3EvJ+oKjc7\nvieusJH8uXo51sD7vb8W/MzPVhix2mNuflmJz19mnVXnSbauhyStUDXf+FR9vb0PTXymTsosf77C\n6c2Vz+2Nkr4f/7+2yfXUp9yK8x5WtV5mZtaxK1xPv1Iz302Z6UMlPZKp66U4zzRJuyU+T01/Dzb4\nWd9IC34Hva6enH9T4VTbZP2STs3k3jsTy1xXPTn/vb7kebOvM1N2HUmPZl7XWzHPq79vb0jMu7ak\nZ6vWyazM/ztmpm3WTJ7z4MGj8QdHRIE28XBLjnUVNrb+pXAk41WF+64dKGl7r3+bgHp1u7sfq3Aa\n7c8VOhBvKQxWMlNhj/2PJX3Q3e+Q3j7l6tJYZqpqn2r0ZYUjqctKuqiytzz6jKRDFTbG5ioMXvQP\nhQ7RhxR+8Aech9PEPijpNwobEaZwHd9PJG3gfbhXpYcjxx9WGFl2ssJGywiF62ynKRyxOlT569r2\nVDj6c2Nsw8IKufCEwp74rd39a+oDdz9B4fS6s9VzquPCCvl2qcKpmrVuH1Rd1yyFdXZyfD1vKexk\nuEXhtj5fqDP7VxSOJl0Tl20K1xs/o7CudnX33X3Ba4u/K+mrkq5U2Difp3C6+gsK92rcT2EDutZR\nvn7h7r9TOEp9nMJ1068odNLnKpwee46kcUrc4N7d/6BwT8LLFF7Hwgr3KvyZwj0tm867qvrPVejs\n3qSeU7P/qXAP14+q9hHRsyQdpJATUxU6CksofFf8WSFv3+9Vg9b0N3c/TCFHb1HoLA5X+C47QuFI\naeUMgllNVt3n3HL3kxSOCF6sMNLuCIVTee9W6KRu4vXvj1uTh6PuWyvk0OMKr2/1+Oiv0WZT7bhP\nYVyAKxR2siyksP6vUPjNuCg1XzxL5ivx6Zc8cb9Qd39QPbdzOTJeDlEId39Y4Tfx8wpjL0xXyHNT\n+H78lcLnYI/EvI/EeU9V+P4zhd+OKyRtpgXvD9psPgJokLn7QLcBAJpmZmMVrvOTd9mtNQDkmdkd\nCjtHjnX37/ZWHugvZvYxhc7t65KW8L7dcxdALzgiCgAABpSZfVQ9I+peW68s0J/iYFqV64dvohMK\n9B86ogAAoN+Z2elmNj4OiGUxtlQc/OyqWOwmd+/LrVKAhpnZlmZ2spltbGaLxpjFgQZ/r3BKtUv6\n0UC2Eyi7Ikc4AwAAg9eH1DP68Fwze03hetzKqfUPqWeEW6A/LSnpkPiQmc1UuM69chswl3S4u986\nMM0DBgc6ogAAoAjHKoxS/AFJo9Uz2NqDCrdXOsvdW7nlDTpAvN1R7t63vdjE3Z/sj/bUcLfCvZK3\nlvROScvF+H8UBvT6mbvfW2B7gEGJwYoAAADQFmY2TWFk4Ga8w92ntb81ADoZHVEAAAAAQKEYrAgA\nAAAAUCg6ogAAAACAQtERBQAAAAAUio4oAAAAAKBQdEQBAAAAAIWiIwoAAAAAKBQdUQAAAABAoeiI\nAgAAAAAKRUcUAAAAAFAoOqIAAAAAgELREQUAAAAAFIqOKAAAAACgUHREAQAAAACFoiMKAAAAACgU\nHVEAAAAAQKHoiAIAAAAACkVHFAAAAABQKDqiAAAAAIBC0REFAAAAABSKjigAAAAAoFB0RAEAAAAA\nhaIjCgAAAAAoFB1RAAAAAECh6IgCAAAAAApFRxQAAAAAUCg6ogAAAACAQtERBQAAAAAUio4oAAAA\nAKBQdEQBAAAAAIWiIwoAAAAAKBQdUQAAAABAoeiIAgAAAAAKRUcUAAAAAFAoOqIAAAAAgELREQUA\nAAAAFIqOKAAAAACgUHREAQAAAACFoiMKAAAAACgUHVEAAAAAQKHoiAIAAAAACkVHFAAAAABQKDqi\nAAAAAIBC0REFAAAAABSKjigAAAAAoFB0RAEAAAAAhaIjCgAAAAAoFB1RAAAAAECh6IgCAAAAAApF\nRxQAAAAAUCg6ogAAAACAQtERBQAAAAAUio4oAAAAAKBQdEQBAAAAAIWiIwoAAAAAKBQdUQAAAABA\noeiIAgAAAAAKRUcUAAAAAFCoruyImtnmZnaFmT1jZm+Y2Qwzu8HM9jWzIQPdvmaY2S5m9rUmyruZ\nHd+G5Y6Pdb2r1bpifWNjfWN7KTfSzE40s1vMbHYj8wxG5Hj35ngsu7SZnWNm083sVTP7k5m9tx3t\nKAtyvOtzfAMzu9bMXonf5ZPb1Y4yIL+7N7/NbFIsl3o80o62lAE53r05Hst2xHZK13VEzexQSXdI\nGiVpgqRtJO0n6Z+SzpC048C1rk92kdRw8pfAMgrv1zxJNwxwWzoSOd7dzMwk/V7SdpK+ImlXScMk\n3Wxmqwxk2zoFOd7dzGxNSX+WtKSkz0j6nKQxkm4zs+UHsGkdgfzuet+VtHnVY684bfJANaqTkOPd\nrZO2U4YWubBWmdkWkn4q6Wfu/tWqyVeZ2U8lLdaG5Qx397mJuEka5u5vtLqMQewJdx8lSWa2jaRP\nDXB7Ogo5Xgo7SfqQpK3c/WZJMrO7JD0u6RuSqt/XQYUcL4UJkt6StL27z5IkM5si6TFJhyvk+aBE\nfnc/d/+3pH9nY2b2sfjvBcW3qLOQ46XQMdsp3XZEdIKkl1TjR87d/+3uf688N7NN46HmV+Jh5xvN\nbNPsPPEUjKfiKQZ3mtn/JP0oTptmZheb2X7xdIw3JH0iThthZj80s8fjKQmPm9k3zWyhqvqXM7Of\nm9mTZjY3/r3IzIab2SRJ+0paOXPax7RWVpCZLWJmJ5nZ1Pi6nzOz35vZ2jVmWcnMfhfLzjCz081s\n0ao6G3qtjXB379MLGzzI8V50eo4rfME/U/lylyR3f1lh7+POfaivbMjxXnRBjm8m6a5KJ1SS3P0p\nSVMljetDfWVCfveiC/I7ZR9J97n7g22qr5uR473oghzvmO2UrjkiauF88y0l/c7dX2+g/Psk3Srp\nIUnjJbmkIyXdamabufsDmeJLSrpM0omSjpb0v8y0LSVtIOk4SS9ImmZmQyVdJ+k9Cqdw/EPhh/kY\nhdMUvh7bsLSkO2PseEl/l7S8wpu8cJx3OUmbKCSFJOX2/jRpuKSRcXnPxmV/SdJdZraOuz9XVf5i\nSVdI+rmkTSUdq7Ana3x8DQ291hQzGy/pfElbuvstLb6u0iPHG9bpOb6uwgZ5tQcl7WNmi7v7K828\n4LIgxxvW6Tn+lsLGYLW5ktYws0UaeX/LhvxuWKfnd3WZD0l6lwb52SwSOd6ETs/xztlOcfeueEga\nrZDAJzRY/teSZklaKhNbQmF4HgQSAAAgAElEQVQvzm8zsUmx3p0TdUyT9JqkFarie8d5tqiKf1Ph\nx3n5+Pw7Cj/YG9Zp5yRJTzWxHlzS8U2UHyJphKQ5kg7LxMfHus5MvIa3JL27ydc6NpYbmymzj8K1\noB+t0bZtqucZzA9yvBw5rnCNzGWJdh4Q5191oHNtoB7keGly/ApJTymcHleJjYzvlUtacaBzjfwm\nv/ua34n2/SLWs+xA59hAP8jxcuS4Omg7pdtOzW3GFpKu9gVPHZqtcKH5R6vKvinp6hr13O35PRfb\nSXpC0p1mNrTykHS9wsW+m8Vy20q6x93/2tpLaY6Z7WFmU8xslkLyvSppcUlrJYpfUfX8MoVTtiun\nTTT6WnPc/UJ3H+rut7b2ilADOU6Olx053pk5fqqklSWdaWYrm9nqCnvcF4/T5zfzWgcx8rsz8zvb\nzkUk7aHwPk1v/BUiIsc7PMcHWtecmitphsJh+tUbLD9K4XB4teckLV0Ve9Hd36pRT6qO5WM73qwx\nzzKZvw/UKNMvzOyTki5XuKD+OEnTFTYKrpG0SGKW52s8Xzn+bfS1onXkeAO6IMdnKr/+pfB+VaYP\nVuR4Azo9x939djP7sqQTFEbKlKQ/xfZ+VuFox2BEfjeg0/O7yk6SlhKDFFWQ4w3oghzvmO2UrumI\nuvs8M7tF0sesxkhaVV6StEIivoLyK9jrLToRm6EwstQeNeaZFv9OV08SFWVPSY+5+/hKwMyGqSe5\nqo1WOCc8+1ySno5/G32taBE53rBOz/EHFfbAVnuPpP/6IL0+VCLHm9DpOS53/7mZnatw7dxsd3/S\nzP4oaYq719pYKjXyu2Edn98Z+yqso2taqKM0yPGGdXqOd8x2SredmvsDhV7/j1ITzewd8cJoKVwc\nvYOZjcxMHynpk5JuabEd10paVdIr7n5v4lE5feN6SZua2fp16poradE605s1QuEUgKy9Fc5PT6lO\n6j0V9tpMic8bfa1oD3K8d52e45MVRt97+7QjM1tC4X3hHnTkeCM6PcclSe4+190fjJ3Q9ypc939G\nX+oqEfK7d12R32Y2WtLHJf1ysO5cqYEc712n53jnbKd4QRejtush6VCFN+cGhRtpf0Th1IlTFM6/\n3jmWe5/C6QN/UbhR66cU3tD/SVo/U98k1bhAWWEPw8WJ+DCFD9fTCjfA3VrS9pIOVkj4EbHcUpL+\nJelFSYdI2koh2S6RNDKWOURhT88XFUbsem8vr98VLv7eLfFYWtLnY5mTYrsmKAwqMVPSpEw942O5\n/0r6saSPqeei5/P78FrHqsFBAOL8uymcruCSvh2fbz/Q+dUJD3K8u3NcYQffnZKeVPgx+bjCD+5L\nGsQDFZHjpcrxVSR9T+EWCtsojIL5sqTLBzq3OuFBfnd3fmemfS2Wf/9A51SnPcjx7s5xddB2yoAn\ncx8/AB+U9CuFc8bfjCvueoVrUxbKlPuAwnUrr8QPxo2SNq2qq+nkj9MWkTRR0iMKe1JeknRPjA3N\nlFte0lmxrW/EN/0CScPj9MUkXRqT0yVNayD5az02jsl1vKRnFEYZu1XShvG1pJJ/C0lXxXX0kqTT\nJS3a7Gutkfzjq2OZ9Zpqf93XPpge5HjX5/goSefFel6L78v69V73YHuQ492b4wqnjf1J4ZS3uQq3\nZvh6dp0N9gf53b35nZn2gKR/DHQudeqDHO/uHFeHbKdYbAwAAAAAAIXotmtEAQAAAABdjo4oAAAA\nAKBQdEQBAAAAAIWiIwoAAAAAKBQdUQAAAABAoTqqI2pm483MM485ZvaAmR1sZkMLWP5EM/OqmJvZ\nxCbrOdTMPtXWxoV6p5nZpF7KjIltPqANy5sY62rLus+8v2N6KbeKmZ1mZneZ2WuNzNMtyPFe6x0U\nOR7Lrmpmvzazl81stpn91sxWa0c7Bgr53Wu9gym/tzSz283sf2b2kpldZGaj29GOgUSO91rvoMhx\nM7ulKg+yj2vb0ZaBQo73Wu+gyPFYtt+3U/o9ofpod4Ubvy4R/z9N4R5Axw5AWzaPbWnGoZJul/Tb\n9jdnUHiXws2G75P0Z0nbDmxz+gU5PoiZ2QhJNyncC2xfhXt8HS/pZjN7n7u/OpDtawPyexAzs48o\n3E/wOoWb2C+jkN83mtlG7j53INvXJuT44PYlhfc+a3NJP5U0ufjm9AtyfBArajulUzuif3P3x+L/\n15vZuyQdohrJb2YmaZi7v9Huhrj73e2uE726zd1HS1Lcm1TGjig5PrgdKOmdktaq5IGZ/V3SvyR9\nXmFjppuR34PbtyU9IWkXd58nSWb2sMLN1/eX9PMBbFu7kOODmLs/VB0zswMlvSHpsuJb1C/I8cGt\nkO2Ujjo1t457JC1hZstLbx8Wv9jM9jOzRxQ++J+I00aY2Q/N7HEzeyP+/aaZLfBazWxDM/uzmb1u\nZk+b2TGSrHrBqdMBzGx9M7vSzGbE044eNbOjKm2TtLqkz2ROa5hUNe9kM5sZ570j7j2uXu4h8XW+\nbmb3psr0lZktZ2a/MLN/Wjj19Ukz+6WZrVxjlnXM7OZY9lkz+05ifS5nZmfGdTnXzB4xs4P60j53\nn9+X+bocOT6IclzSTpLuzvzIy90fl3SHpJ37WGcnI78HV35vJumGSidUktz9XkkzJI3rY52djhwf\nXDle3d4RCkcNf+/uL7Wjzg5Ejg+uHC9kO6VTj4hWe4ektyS9koltKWkDScdJekHSNAvnT18n6T2S\nvivpHwo/iMdIGiXp65JkZssqHG5+TuFw81xJR0jq9bxnM9tU0i2SHpN0mMKpAmtKel8sMk7SNZIe\nkDQxxl6M875f4VTTvyrsaXhN0hck/cnMPuju98Vy+0s6WdIkSZcrnKp6qaSRvbWvQaMkvS7pqNi2\nlRTWzR1mtra7v15V/neSzpN0gqSPK6zP+ZXXZ2ZLKJz+sGiMPR7LnWFmw939tFoNiV8s35b0Dnef\n1pZX153I8cGV4+tKuipR/EGFjZmyIb8HV36/pbBRWm2upPWaeqXdgxwfXDlebZzCa7+guZfZVcjx\nwZXjxWynuHvHPCSNVzgHeS2FTvLSCod/35L0u0y5aQqJs0LV/HvH+beoin9T4Udx+fj8e/H5qpky\ni0maHlbJAvO6pImZ57dJelLSiDqvY5qkixPxGyU9LGnhTGxIjP0uPl8o1n9t1byfjm2Z1Ms6HBPL\nHdDEeh8iadU437hMfGKMHVlV/mxJcyQtFZ8fo/BhWjNRbrqkoVXv75hMmWMlzZO0eo22HVA9Tzc/\nyHFyPMbekPSDRDuPlzRvoPOU/Ca/W8zvv0iaUlXX6gobTXMHOk/JcXK81RxPtO86Sc9X6unmBzlO\njsdYIdspnXpq7iOS3pT0ksK1JJdI2q+qzN3u/lxVbDuF61LuNLOhlYfCoAnDFPbISOGi57vd/cnK\njB4uuv19vUbFUy8+JOkSd3+tmRdkZotK+qikX0man2mbSfqTpC1i0VXi44qqKn6jkCRtYWZftDAK\n2iux3v/GSWslile35TJJi6tnz/Z2kqZIerxqvV+nMEjFe2q1w92/4+5D3f2JFl5ONyLHyfEyI78H\nd36fImlTMzvezJY3s7UlXaTQES3LpRfk+ODO8Ww7V5K0jcI6b9vr7wDkODne7zr11NxxCofZ50h6\nwvOHpyXp2URseYW9rm/WqHeZ+HdFSVMT05/vpV1LK+wlaXbkLikcgh+isMfimFSBeK73iqm2uPs8\nM5vRh+WmlvMVSacqXGh8hKSZCq/rbkmLJGapXi+V55Xz2JdXOGWht/WOHuT44M7xmQrrutqoOK3b\nkd+DOL/d/ZLY+Txc4SiIK5zado3Kc2ouOT6Ic7zKZ2PbynZaLjk+uHO8kO2UTu2ITvXMxbE1eCI2\nQ+Gc6D1qzDMt/n1WUup+Zr3d42ymwt7cWhcS1zMrznu6pAtTBdx9vplVPtQLtCXu1WhXh25PSTe6\n+9cz9b+jTvnRkv5T9VySno5/ZyhcG3BIjfkf7WM7y4wcH9w5/qDC9RfV3iMpNxpjFyK/B3d+y92P\nMbMfKIy6+IK7P29h5Nzbm62rQ5HjgzzHM/aV9IC7P9BCHZ2IHB/cOV7IdkqndkT76lqFe5a94u6P\n1Cl3l6QjzGzVyikBZraYpE/Wq9zdXzOz2yV91sy+4+7/q1F0rsLFwtl5XzWzP0taX9L9Xntk2KcU\nzkvfQ+Gi5Ipd1b73a4Sk2VWxz9Upv4ekH2Se76lwsfo/4vNrJX1F0n/d/YU2tRFp5HhjOj3HJ0s6\n0cze6e7/kSQLN5f+kKQj21B/tyK/G9Pp+S3p7dPs/iFJZradpLUVbt8ymJHjjemKHDezjRU2zL/W\nrjpLgBxvTKfneCHbKWXriF6i8CbeaGY/URgta2FJaygMQ7xLPJ/8JIWbEV9vYaSoykhdtZI563BJ\nt0q6Ky7jKYU9vhu4+1dimYckfcTMdlQYDWy6h1GovqZwgfV1Znauwt6gZSW9X9IQdz8y7ok5TtI5\nZna+wjng71J406sTtp6NzGxWIj5ZIVknmNnRCoNKbCVptzp1HRhPVbhHYQSuAxQuGn85Tj9J4QLu\nP5vZSQp7XRZT2Oj4iLvXHObZzI5VuEh6jey56WZWac9G8e/2ZvaipBfd/dY6bS07crxHN+f42ZIO\nlnSVmX1LYa/ydxV++H7R6ysvL/K7R9fmt5ltKGl7SffHYh9WeH9+5O539vrKy40c79G1OZ6xj8K1\nfZfUfaWDCzneo5tzvJjtFO+AEboqD/WM5PSuXspNU2IkrDhtEYURph5RSOqXFN60icqMZqaQcH9W\nGGHqaYVzxY9TLyN1xdiGChdTz1L4wDwiaUJm+tqx7tdUNbqWpHUUEvqF2L6nFBJyh6plHKJwsffr\nku5V+CGfpsZH6qr1WFZhD9EZCsNFz5F0tcKw3NWjkk2MsfUk3Rxf63MKibhQ1XKXVvgQPK4w0tYL\ncR0cmnh/xySWMSax3lOPWwY6T8lxcrxNOb6awsAHs2Mbf1ddptse5Df5HWPrKpyCW1m/90v63EDn\nJzlOjrcrx2N8WGzf7wc6L8lxcryfcrzft1MsLggAAAAAgEJ06u1bAAAAAAAlRUcUAAAAAFAoOqIA\nAAAAgELREQUAAAAAFKql27fE+4KdImmIpHPc/Qe9lGdkJBRhursv146KyHF0qAHJcfIbBeE7HGVH\njqPsGsrxPh8RNbMhkk5XuFfYeyTtZWbv6Wt9QBtV3+erT8hxdDByHGVGfqPsyHGUXUM53sqpuZtK\neszd/+Pubyjcj6fmzVKBLkSOo+zIcZQZ+Y2yI8fR1VrpiK4s6cnM86dibAFmdpCZ3Wtm97awLGAg\nkOMou15znPxGF+M7HGVHjqOrtXSNaCPc/SxJZ0mcl45yIsdRZuQ3yo4cR9mR4+hUrRwRfVrSqpnn\nq8QYUBbkOMqOHEeZkd8oO3IcXa2Vjug9ktY0s3eY2cKS9pQ0uT3NAjoCOY6yI8dRZuQ3yo4cR1fr\n86m57j7PzA6WdJ3CkNHnufuDbWsZMMDIcZQdOY4yI79RduQ4up25F3eqOOeloyD3ufvGA7FgchwF\nGZAcJ79REL7DUXbkOMquoRxv5dRcAAAAAACaRkcUAAAAAFAoOqIAAAAAgELREQUAAAAAFIqOKAAA\nAACgUHREAQAAAACFoiMKAAAAACgUHVEAAAAAQKHoiAIAAAAACkVHFAAAAABQKDqiAAAAAIBC0REF\nAAAAABSKjigAAAAAoFBDB7oBCEaOHJmMT548ORcbO3Zssuwqq6ySiz399NMttQvob4cddlgu9tOf\n/jRZ1t0brnfJJZfMxebMmdN4wwAAABLGjRuXjP/mN7/JxcwsWbaZbZpXX301F6vVd+gmHBEFAAAA\nABSKjigAAAAAoFB0RAEAAAAAhaIjCgAAAAAoVEuDFZnZNElzJL0laZ67b9yORg1GSy21VDL+kY98\nJBebP39+suwxxxyTi33hC19orWGDHDnePrUG2TrhhBNysVo53oz//Oc/udgXv/jFZNlf//rXLS+v\nW5HjKDtyHGVGfve/Aw88MBc77rjjkmVTAxA1MyhRLcOHD8/FPve5zyXLnn/++S0vryjtGDV3S3ef\n3oZ6gE5FjqPsyHGUHTmOMiO/0ZU4NRcAAAAAUKhWO6Iu6Xozu8/MDmpHg4AOQ46j7MhxlB05jjIj\nv9G1Wj0198Pu/rSZLS/pBjN7xN1vyxaIHwo+GOhW5DjKrm6Ok98oAXIcZcZ2CrpWS0dE3f3p+PcF\nSVdK2jRR5ix335iLp9GNyHGUXW85Tn6j25HjKDO2U9DN+nxE1MwWk7SQu8+J/28r6Ttta9kgs/rq\nq7dcxzvf+c5cbOTIkcmyc+bMaXl5ZUeOt9dRRx2VjA8bNqxfljdq1KhcbI899kiWHayj5pLjKDty\nHGVGfrfXZz/72WQ8Nbr/0ksv3d/NWcCQIUNysdNPPz1Z9qGHHsrFpkyZ0vY2tUMrp+aOlnSlmVXq\n+aW7X9uWVgGdgRxH2ZHjKDtyHGVGfqOr9bkj6u7/kbR+G9sCdBRyHGVHjqPsyHGUGfmNbsftWwAA\nAAAAhaIjCgAAAAAoVKu3b0Gb7L333i3Xsdlmm+Via6yxRrLs3/72t5aXB9Sy//7752Kbb775ALRk\nQR/96EeT8fPPPz8XO/nkk5NlH3jggba2CQD6KvW7f9dddyXLXn311bnY0KHpzcCbb765tYYV7Kyz\nzsrFZs2aNQAtQTcbMWJEMr7MMsvkYvPnz295efPmzcvFXnrppWTZ5ZZbLhcbPnx4suw555yTix15\n5JHJsn/4wx/qNbHfcUQUAAAAAFAoOqIAAAAAgELREQUAAAAAFIqOKAAAAACgUHREAQAAAACFYtTc\nDnH88ccn46nRR2t56qmncrGZM2f2uU1A1qhRo3KxT37yk8myp556ai62yCKLtNyG559/Phf78pe/\nnCx7yimn5GIrr7xysuw+++yTi2288cbJsu9973vrNREdLpXHkvTpT386F1tnnXWSZTfZZJNcLDV6\nqSQ98sgjudhxxx2XLHvZZZcl40AtL774Yi72+OOPJ8vusMMODde77bbb9rlNA+E973lPLjZ+/Pji\nG4Kutu666ybj7t5SvbfeemsyfsIJJ+RiN9xwQ7LspEmTcrFad9xIfR622WabZFlGzQUAAAAADCp0\nRAEAAAAAhaIjCgAAAAAoFB1RAAAAAEChGKyoQ5x44onJuJnlYgstlN5/sNZaa+ViK664YrLsE088\n0UTrMJikck6SJkyYkIsdfvjhDdc7b968ZPyxxx7LxVKDHUnSHXfckYtNnTo1WXb06NG52Omnn16v\niQsYMmRIMr7wwgvnYm+88UbD9aI4qe+/73//+8myqQGrmjF//vxk/N3vfncudv755yfLDh8+PBe7\n4IILWmoXyu3f//53LrbFFlskyy6++OIN1/uJT3wiF9tggw2SZZdYYomG601Zb731kvExY8Y0XMeI\nESNaagMGnwMOOCAXO+igg1qu95prrsnFdtttt2TZuXPnNlzvd7/73Vys1mBFKanfok7AEVEAAAAA\nQKHoiAIAAAAACkVHFAAAAABQKDqiAAAAAIBC0REFAAAAABSq11Fzzew8STtKesHd14uxUZIulzRG\n0jRJe7j7zP5rZrkss8wyudhKK62ULOvuuVit0RlTZVMxLGgw5/ioUaNysdTouFJzI+SmHHnkkcn4\nSSed1FK9/SW1biRpnXXWycUeeOCB/m5OS8qe47VGej7zzDNzsR133LG/m9Or1MjLknTsscfmYh/+\n8IeTZVMj7955552tNayLlT3Hm/HUU0+1XMcjjzzShpbkpXL/wgsvTJZNjZr7wgsvJMuecsopLbWr\n05HfjVlqqaVysdRo+1I6F2t9N6fcfPPNyfi4ceNysVp3DWjG888/39L82223Xctt6A+NHBGdJKm6\n9UdKutHd15R0Y3wOdKtJIsdRbpNEjqPcJokcR3lNEvmNEuq1I+rut0l6qSq8s6TKzc0ukLRLm9sF\nFIYcR9mR4yg7chxlRn6jrHo9NbeG0e7+bPz/OUn5O8dHZnaQpNbvEAsUixxH2TWU4+Q3uhg5jjJj\nOwVdr68d0be5u5tZzQsR3f0sSWdJUr1yQKcix1F29XKc/EYZkOMoM7ZT0K362hF93sxWdPdnzWxF\nSemrx5G05ppr5mKbb775ALQEdQyKHD/jjDNysd12263ler/61a82tKz+dPbZZ+ditT5nn/3sZ3Ox\nZZddNll2/fXXz8U6fbCiGkqT4+uuu24y3urARLNnz07Gn3zyyZbqXX755ZPx1OAs++23X8Nld911\n12TZWq9jEChNjneb4cOHJ+OpAbl23333hutNDQQjSXfffXfDdZTIoM3vNdZYIxk/77zzcrG11167\n5eVddtlluVitARjbMTBRf5gxY8ZANyGpr7dvmSxp3/j/vpKuak9zgI5BjqPsyHGUHTmOMiO/0fV6\n7Yia2aWS7pK0lpk9ZWb7S/qBpI+Z2b8kbROfA12JHEfZkeMoO3IcZUZ+o6x6PTXX3feqMWnrNrcF\nGBDkOMqOHEfZkeMoM/IbZdXXU3MBAAAAAOgTOqIAAAAAgEK1fPsWAJ1v//33T8ZbHVU0NTquJJ15\n5pm52Pz581taVrPeeuutXGzy5MnJsqlRc80sWXbDDTfMxS688MImW4dO89hjj+Vin/rUp5JlH3zw\nwZaW9f73vz8Zv+eeexquY6uttsrFTjvttGTZfffdNxkH+kvqe1KqPdJoyty5c3OxqVOn9rlN6Gy1\nRlr++Mc/nov96Ec/SpZN3ZWiGTfeeGMyPmHChFys1dHTm1Xr96hRxx9/fJta0l4cEQUAAAAAFIqO\nKAAAAACgUHREAQAAAACFoiMKAAAAACgUgxUBJbPFFlvkYieddFKy7CKLLJKLzZs3L1k2NcjEGWec\nkSxb9MBERdprr/zt3A477LABaAkqHn300WT8zjvvzMU++MEPJsumBtiqNSjRiBEjcrFag1vtscce\nudguu+ySLNuqlVdeuV/qBZr1ne98p+GyqYHlJGn77bfPxV555ZU+twmdbamllkrGr7zyypbqnTFj\nRjKeGryn1jbNm2++2VIbmrHWWmsl47vvvntL9RY9uFKjOCIKAAAAACgUHVEAAAAAQKHoiAIAAAAA\nCkVHFAAAAABQKDqiAAAAAIBCMWpuh6g14mLKQgul9x9cfvnludiUKVP63CZ0p3XWWScXW2yxxRqe\n/7HHHkvGa428O9icffbZA90EVKk1ouEzzzzTcB1HH310Lrbeeusly6ZGTh4+fHjDywLKZOLEibnY\nVltt1fD83/jGN5LxW2+9ta9NQodYdNFFk/EjjjgiF/vWt76VLNvM9vHLL7+ci51zzjnJsqeeemrD\n9RZpyy23TMZ33HHHXOyNN95Ilr3ttttysZtuuqm1hvUTjogCAAAAAApFRxQAAAAAUCg6ogAAAACA\nQtERBQAAAAAUqtfBiszsPEk7SnrB3deLsYmSDpT0Yix2tLtf01+NHAzcveGy8+fPb7kO9Chbju+7\n774tzT9p0qT2NKQDvfbaa8l46oL/hRdeOFl2+vTpbW1TEcqW4436yU9+koulBnyQpFGjRuVi48eP\nb3eTJElz585Nxu+4445crNagL6lcHqyDuwzW/O4UO+20Uy5Wa4CZVN4+/PDDbW9T2XRDjqcGJjrr\nrLOSZf/v//6v4XpT27bPP/98suwOO+yQi/3tb39reFlF22abbXKxcePGJcv+8Y9/zMVOP/30ZNnt\nttsuF9t9992TZWsN5lSURo6ITpKUf0XSSe6+QXzw5Y5uNknkOMptkshxlNckkd8ot0kix1FCvXZE\n3f02SS8V0BZgQJDjKDtyHGVGfqPsyHGUVSvXiB5sZn83s/PMbOm2tQjoHOQ4yo4cR5mR3yg7chxd\nra8d0TMkrSFpA0nPSspfiBOZ2UFmdq+Z3dvHZQEDgRxH2TWU4+Q3uhTf4Sg7chxdr08dUXd/3t3f\ncvf5ks6WtGmdsme5+8buvnFfGwkUjRxH2TWa4+Q3uhHf4Sg7chxl0OuouSlmtqK7PxufjpM0tX1N\nQl+ddtppA92E0ujmHJ86Nd/UD3zgA8myqdHo1llnnba3qVM8++yzyfjMmTNzsdGjRyfLfuMb38jF\nTjnllNYaNgC6Occb9Ze//CUXO/7445NlJ0yYkIuNHDkyWXbOnDm5WK3RlI855phc7Prrr0+WnT17\ndi523333JcuuttpqudjkyZOTZQejwZDfRdt+++2T8TXXXDMXS31GJOmLX/xiLnbddde11rBBqtNy\n/IgjjsjFmhkdtxn7779/Mt6pI+Sm8l6Svve97+ViM2bMSJb9+c9/nouddNJJybJrrLFGLnbqqafW\na+KAaeT2LZdKGitpWTN7StK3JY01sw0kuaRpkj7fj20E+hU5jrIjx1Fm5DfKjhxHWfXaEXX3vRLh\nc/uhLcCAIMdRduQ4yoz8RtmR4yirVkbNBQAAAACgaXREAQAAAACF6tNgRWjNPvvs0y/1PvHEE/1S\nLzrTBhtskIzvvPPODdfx+OOP52L77bdfn9vU6VIX8Eu1ByZK+eY3v9mu5mAAnHDCCcn4L37xi1xs\nhx12SJZNDQo0atSoZNlp06Y13riEefPmJeOpgZRqDSbzwAMPtNQGDD7jxo3LxSZOnJgsO2LEiFys\n1qAxl156aUvtQuf61re+1dL8L774YjJ+1FFH5WK1BnzrBFtssUUutv766yfLLrnkkg3FJOnEE09s\nuA33339/LpYaGKkTcEQUAAAAAFAoOqIAAAAAgELREQUAAAAAFIqOKAAAAACgUHREAQAAAACFYtTc\nAVBr9KxWHXPMMblYrREiGWG3+2244YbJ+LLLLltwSzrTuuuum4udfPLJDc8/c+bMZPyRRx7pc5vQ\nuV566aVc7OKLL254/tmzZ7fchtRI2GuuuWbD8z/66KMttwGQpAkTJuRi6623XrLs3Llzc7FJkya1\nu0nocEOH5rsU7p4se689BzEAACAASURBVPPNN+diX/3qV5NlH3roodYa1gabbbZZLrbqqqsmy6ZG\nYK81Em4zUtvtRx99dLJsav1Onz695Tb0B46IAgAAAAAKRUcUAAAAAFAoOqIAAAAAgELREQUAAAAA\nFIrBigaAmTUUq2WhhdL7Dw488MBcrNaAAQxW1P1Sg0k06w9/+EMbWlKcIUOG5GKnnXZasuxuu+2W\niy2zzDINL+uwww5Lxu++++6G6wCasfjii+diI0aMSJadP39+Lvb666+3vU0oj9R2xk477ZQsu9FG\nGzVc7xFHHJGLnX766Y03DKV1ySWXJOPHHntsLjZt2rR+bs2Cttxyy1xsu+22S5ZN5XitgZiaMWPG\njFys1mfnvPPOy8WefPLJltsw0DgiCgAAAAAoFB1RAAAAAECh6IgCAAAAAApFRxQAAAAAUKheO6Jm\ntqqZ3WxmD5nZg2Z2SIyPMrMbzOxf8e/S/d9coP3IcZQdOY4yI79RduQ4yqqRUXPnSfq6u99vZiMl\n3WdmN0gaL+lGd/+BmR0p6UhJrQ/jOQikRtpqZvSt1GiJkvTf//43F5s+fXrjDRu8ujLHZ82a1XId\nBx10UC72zDPPJMtOmTKlpWUdcsghyfiKK67YcB2pEaM33njjhuev9Xl46KGHcrF//etfDdfbBboy\nx1Hb/fffn4v98Y9/HICWdATyuwEjR47MxX772982PP/UqVOT8d/85jd9bhMa1pU5vsEGGyTj66+/\nfi624447JsueffbZudiwYcOSZb/0pS/lYltttVWy7NixYxuuNzXi9OOPP54s+8tf/jIXO+OMM5Jl\n//e//+ViM2fOTJYtq16PiLr7s+5+f/x/jqSHJa0saWdJF8RiF0japb8aCfQnchxlR46jzMhvlB05\njrJq6hpRMxsjaUNJUySNdvdn46TnJI1ua8uAAUCOo+zIcZQZ+Y2yI8dRJo2cmitJMrPFJf1G0qHu\nPjt7mNrd3cyS55aa2UGS8uf/AR2GHEfZ9SXHyW90C77DUXbkOMqmoSOiZjZMIfEvcffKBQXPm9mK\ncfqKkl5IzevuZ7n7xu7e+IVcQMHIcZRdX3Oc/EY34DscZUeOo4x6PSJqYXfLuZIedvefZiZNlrSv\npB/Ev1f1SwvRsM985jO52GOPPTYALeku3Zrju+++ezKeGjhio402SpYdPnx4LnbCCSe01rAO8eij\nj+ZitQZMuuGGG/q7OQOqW3MctTUzyEzZkd/FSA0aI0nPPfdcwS0ZfLohx2fMmJGLrbvuusmyzXx/\npQZVrFVvf7n00ktzsYsuuihZdhAPGtcnjZya+yFJe0v6h5n9LcaOVkj6K8xsf0lPSNqjf5oI9Dty\nHGVHjqPMyG+UHTmOUuq1I+rut0vKj1scbN3e5gDFI8dRduQ4yoz8RtmR4yirpkbNBQAAAACgVXRE\nAQAAAACFoiMKAAAAAChUw/cRRfvMmjWrX+p94okn+qVedKYnn3wyGd91111zsSuuuCJZdv3118/F\nUiPp9qd58+blYjNnzkyWnTx5ci525513Jstecskludibb77ZZOuAzrTeeusNdBPQZSZMmNDS/Fde\neWWbWoIy2n777XOx1G+2JI0ePbrhelsdIfemm25Kxi+//PJcbJVVVkmWPffcc3OxWttgaA5HRAEA\nAAAAhaIjCgAAAAAoFB1RAAAAAECh6IgCAAAAAArFYEUD4IADDsjFrr766mTZ1GAyX//615NlX375\n5dYahlJIXUC/+eabJ8vuvPPOudh73/veZNnjjjuutYbV8MMf/jAXO/bYY/tlWUAne/jhh3OxadOm\nJctOnTq1n1uDshk1atRANwEldu+99+ZiG264YbLsJptskottvfXWybLPPfdcLvbPf/4zWfavf/1r\nLjZjxoxk2Tlz5iTjKBZHRAEAAAAAhaIjCgAAAAAoFB1RAAAAAECh6IgCAAAAAApFRxQAAAAAUChz\n9+IWZlbcwjCY3efuGw/EgslxFGRAcpz8Lt7999+fjKdGzd1nn336uzlF4Tu8BSuuuGIyfuedd+Zi\nq622WrLs5MmTc7G99torWfb1119vonWIyHGUXUM5zhFRAAAAAECh6IgCAAAAAApFRxQAAAAAUCg6\nogAAAACAQg3trYCZrSrpQkmjJbmks9z9FDObKOlASS/Goke7+zX91VCgv5DjKDPyu5w+/elP52IX\nXXRRsuwNN9zQ380ZUOT4goYPH56ML7/88g3XMW3atFyMQYkGDjmOsuq1IyppnqSvu/v9ZjZS0n1m\nVvlVO8ndT+y/5gGFIMdRZuQ3yo4cR9mR4yilXjui7v6spGfj/3PM7GFJK/d3w4CikOMoM/IbZUeO\no+zIcZRVU9eImtkYSRtKmhJDB5vZ383sPDNbus1tAwpHjqPMyG+UHTmOsiPHUSYNd0TNbHFJv5F0\nqLvPlnSGpDUkbaCwl+YnNeY7yMzuNbN729BeoN+Q4ygz8htlR46j7MhxlE1DHVEzG6aQ+Je4+28l\nyd2fd/e33H2+pLMlbZqa193PcveN3X3jdjUaaDdyHGVGfqPsyHGUHTmOMmpk1FyTdK6kh939p5n4\nivGcdUkaJ2lq/zQR6F/kOMqM/O5u//3vf5Pxp59+Ohcr++i4tZDjC0qNeCtJ48aNy8UOP/zwZNlr\nrmHg1U5CjqOsGhk190OS9pb0DzP7W4wdLWkvM9tAYRjpaZI+3y8tBPofOY4yI79RduQ4yo4cRyk1\nMmru7ZIsMYndZSgFchxlRn6j7MhxlB05jrJqatRcAAAAAABaRUcUAAAAAFCoRq4RBQAAA2DfffdN\nxu+5556CW4Jud/311zcUA4CicEQUAAAAAFAoOqIAAAAAgELREQUAAAAAFIqOKAAAAACgUHREAQAA\nAACFMncvbmFmL0p6Ij5dVtL0whZeLF7bwFrd3ZcbiAVncrwb1lNf8doG3oDk+P+3d+fxdo13///f\nH4kQjZpDDDUU1VA1pFpFcdMaWhStob1JDDeVUjMJXzMt/alqvy2a++ZObnPREsONSI01VJIaE9OX\nqGgiMYQkyCCf3x9rnTrOuvY56+xh7b2u/Xo+Hvtxzv6ca699rb3f2dmfvde+No/hUSjDvrXCY7hU\njtuqWuxbc5HxxmPfmitXxgttRD9zxWYT3H1IU668wdg3xHw7sW+Q4r6t2DdIcd9W7BukuG8r9q0c\nODQXAAAAAFAoGlEAAAAAQKGa2YiOauJ1Nxr7hphvJ/YNUty3FfsGKe7bin2DFPdtxb6VQNM+IwoA\nAAAAaE8cmgsAAAAAKBSNKAAAAACgUIU3oma2q5m9aGavmNmIoq+/nszsKjObaWbPdaqtaGbjzOzl\n9OcKzZxjtcxsLTO738wmm9nzZnZsWo9i/xqJjJcDGa8eGS8HMl6dmPItxZtx8l29mDIea76l9sh4\noY2omfWR9HtJu0kaLOlAMxtc5BzqbLSkXbvURkga7+4bSBqfni+jRZJOdPfBkr4h6afpfRXL/jUE\nGS8VMl4FMl4qZLyXIsy3FG/GyXcVIsz4aMWZb6kNMl70O6JbSXrF3V919wWSbpC0V8FzqBt3f0jS\nu13Ke0kak/4+RtL3C51Unbj7dHeflP4+R9IUSWsokv1rIDJeEmS8amS8JMh4VaLKtxRvxsl31aLK\neKz5ltoj40U3omtIeqPT+WlpLSaruvv09PcZklZt5mTqwczWkbS5pCcU4f7VGRkvITLeK2S8hMh4\nbu2QbymyDJDvXmmHjEeXgVgzzmJFDeTJd+OU+vtxzGyApFskHefuH3T+Wwz7h9rEkAEyju7EkAEy\nju6UPQPkG92JIQMxZ7zoRvRNSWt1Or9mWovJW2Y2SJLSnzObPJ+qmdmSSoJ/rbv/KS1Hs38NQsZL\nhIxXhYyXCBnvtXbItxRJBsh3Vdoh49FkIPaMF92IPilpAzNb18z6STpA0tiC59BoYyUNTX8fKum2\nJs6lamZmkq6UNMXdL+n0pyj2r4HIeEmQ8aqR8ZIg41Vph3xLEWSAfFetHTIeRQbaIeOWvKNb4BWa\n7S7pUkl9JF3l7hcUOoE6MrPrJe0gaWVJb0k6S9Ktkv4o6QuSXpe0n7t3/RB1yzOzbSU9LOlZSYvT\n8mlKjk0v/f41EhkvBzJePTJeDmS8OjHlW4o34+S7ejFlPNZ8S+2R8cIbUQAAAABAe2OxIgAAAABA\noWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAA\nUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAA\nABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAA\nAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAA\nAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQA\nAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEF\nAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhE\nAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCga\nUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSK\nRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACF\nohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABA\noWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAA\nUCgaUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAAAABAoWhEAQAAAACFohEFAAAA\nABSqlI2omW1tZn80s3+a2QIze8fMxpnZUDPr0+z59YaZfd/MTujFeDez8+twvcPSba1f67bS7e2Q\nbm+HHGM3M7O7zWyumX1gZmPrNY9YkPHyZtzM1knHhU7L12MuMSDjpc74TmZ2jZn9PzP7KP15uZkN\nrMc8YkC+y5vvwOWuSC93TT3mEQsyXu6Mt8pz8dI1omZ2nKS/SlpR0qmSdpZ0qKSXJF0u6XvNm11V\nvi8pd/jLzsw2kPSwpOUk/VjSIZLWkfQQT2ISZDwav5C0dZfTnKbOqEWQ8dL7iaSVJJ0vaVclWd9T\n0uNmNqCZE2sF5DseZraNpH+X9EGz59JKyHi5tdJz8b5FXlmtzOxbki6R9Dt3/1mXP99mZpdI+lwd\nrmcpd58fqJukJd19Qa3X0cZOlfSJpN3cfbYkmdkTkl6RdJKkU5o4t6Yj41F51d0fb/YkWg0Zj8Jw\nd5/V6fyDZvaSpAcl7SfpquZMq/nIdzzMbElJf5B0gaQjmzydlkHGo9Ayz8XL9o7oqZLeVYUbyN3/\nn7s/03HezLYys/vSt53nmdl4M9uq82XMbLSZTUsPMXjUzD6S9Mv0b1PTw48ONbMXJC2Q9N30b8uY\n2UVm9lp6SMJrZna6mS3RZfurmNllZvaGmc1Pf15tZkuZ2WhJQyWtYZ8euje1lhvIzJY2s1+b2XPp\nfs8ws9vNbKMKF1ndzG5Nx75jZr83s/5dtplrX3P6hqTHOoIvSe4+TdJzkvauYnuxIeM9KEHG0T0y\n3oNWz3iXJrTDk+nPNXq7vciQ7x60er47OVlSH0kX17CNGJHxHpQg4y3zXLw074hacrz5jpJudfeP\nc4zfVMmrs5MlDZPkkkYoeeX2G+7+dKfhy0m6QcmDzWmSPur0tx0lbSbpHEkzJU01s76S7pE0WNJ5\nkp5VcqeeoeQwhRPTOawg6dG0dr6kZyQNlLSXpH7pZVeR9DUlhzVJUubVn15aStKy6fVNT697uKTH\nzOzL7j6jy/hrJP1R0mWStpJ0ppJXsoal+5BrX0PMbJik/5a0o7s/kJY/UfIg0tV8SV80s6Xz3L8x\nIuO5tXrGO/zCzK6QNE/J/XS6uz9bzQ7HgoznVpaMd7Z9+nNKvl2MD/nOreXzbcln5f6PpO+6+0Iz\nq2V/o0HGc2v1jLfOc3F3L8VJ0qpKAvyLnONvljRb0vKdap9X8irOnzrVRqfb3SuwjamSPpS0Wpf6\nQellvtWlfrqSO3Zgev5cJXf25t3Mc7Skab24HVzS+b0Y30fSMko+m3Z8p/qwdFtXBPbhE0kb9nJf\nd0jH7dBpzMGSFknavlPtj5KmKTmsoqO2bHpfuaRBzc5as05kPJqMD5J0haR9JG0n6T8kvZbO78vN\nzhkZJ+O1Zjwwv2UlvaDkyWbfZuesWSfyHU++JY2TdE2X2/mavPsU64mMx5FxtdBz8ZgPO/uWpDv8\ns287fyBprD595bbDQkl3VNjO45595WJXSa9LetTM+nacJN0raUklr1JI0nckPenuf69tV3rHzPYz\nsyfMbLaS8M2TNEDSlwLD/9jl/A1KDtnuOGwi775muPv/uHtfd3+wU/m3Sg7dusLM1jCztZW8UtOx\nwMXi3uxrmyPjLZhxd5/u7j9x9z+5+8Pu/p9K7itX8p8G8iPjLZjxLvPsK+l6JY/rB7j7otw7CfLd\ngvk2s39X8u5YxXeZkBsZb8GMq4Wei5epEX1Hydv0a+ccv6KSt8O7miFphS61We7+SYXthLYxMJ3H\nwi6nv6V/X6nTz2k551sXZraHpBuVHB71I0lfV/KAOkvS0oGLvFXhfMfnfPLuay7u/oikn0r6gZLb\nZqqSwzHGKHlV593ebC8yZDyHVs94iLu/IemRdJ7tjIznUJaMp59NGqNkxczve6fPhbUp8p1DK+fb\nklWfL5F0kaT5Zra8JV+7tYSkJdPzS+bdXoTIeA6tnHGptZ6Ll+Yzou6+yMwekPRtq7CSVhfvSlot\nUF9N0ntdN9/dVQdq7yg51G6/CpeZmv58W8Uv3HCApFfcfVhHIX3QXLHC+FUlPd/lvCS9mf7Mu6+5\nuftlZnalpPUlfeDub5jZ/0p6wt0X9nZ7sSDjubV8xrvR3f0QPTKeW1kyfoWk/SX9wN3HV7mNaJDv\n3Fo53ysr+bzgz9NTZ2ul17G3pFt7sc1okPHcWjnjklrnuXhpGtHUhZIeULKS1rFd/2hm60paNn1V\n9kFJu5vZsu4+J/37spL2SLdRi7sl7Stprru/0M24eyX9HzP7qn/2A9mdzZfUv8LfqrGMkkMAOjtI\nyfHpIftJ+kun8wcoeUv+ifR83n3tlfTB63lJMrOvKHlF/eB6bb/EyHjPSpHxzszsC5K2VZs+eemC\njPes5TNuZr+SdLikoe5Orj9FvnvWyvmeoWRhnK5uULJAzAVKVhZtZ2S8Z62c8X9piefiRX0YtV4n\nSccpuXPGKfkS1u2UrHL1GyXHX++VjttUyeEDf1Ny5+2j5A79SNJXO21vtCp8QFkVPpyu5HjsB5W8\nUnGCpJ0k7SbpaCWBXyYdt7ykl5W8FX+spH9TErZrlfwjVVp3SUcpedv+Kz3svyv58PcPAqcVlHzX\nlUv6dTqvU5W87f6epNGdtjMsHfcPSf+fpG/r0w89/3cV+7qD8n1Aek0lD+TfVRL4EZLel3Rjs7PV\nKicyXvqM/yqd235KntD8RMlnO2ZL+lKz89UKJzJe+oyfmo67UslnkzqfvtjsfDX7RL7Lne/e3M7t\neiLj5c64Wui5eNPDXOU/gG9KuknJMeMLlbz1f6+kf5e0RKdxX5d0n6S56T+M8ZK26rKtXoc//dvS\nks5WslLg/HQOT6a1vp3GDZQ0Kp3rAklvKDkGe6n0759TstDDe2l4puYIf6XTECWfYzhf0j+VrDL2\noKTN030Jhf9bkm5Lb6N3Jf1eUv/e7muF8A8L1FZN75O3021NVrIgQNuutEjGo8v4oell30vvuxmS\nrhNNKBmPJ+MPdDP/0d3te7ucyHd5893b27ldT2S8vBlXCz0Xt3RCAAAAAAAUokyr5gIAAAAAIkAj\nCgAAAAAoFI0oAAAAAKBQNKIAAAAAgEK1VCNqZsPMzDud5pjZ02Z2tJk1/DtPzexsM/MuNTezs3u5\nnePMbJ+6Ti7Z7lQzG93DmHXSOR9eh+s7O91WXW77TvfvOjnG7mhmj5jZR2b2rpldbWar9nS5VkfG\ne9xuW2TczHbokoOO0+x6zKNZyHeP222XfP/AzG4xs9fTx/AXzewX6fcHlhoZ73G7bZHxwOXuTi93\nfj3m0UxkvMfttk3Gi3gu3vBAVemHSr5v5/Pp7/9XydLLZzZhLlunc+mN4yQ9IulP9Z9O/MxsOyVL\ngN+j5HunVlKyDPZ4M9vSky/gLTsyDkn6mZLl1zt0/QLssiLf7e0kJd+Ld5qS235zJV8xsKOZfdPd\nFzdxbvVCxiFJMrMDJX212fNoADLexop6Lt6qjehT7v5K+vu9Zra+ki+bDYbfzEzSku6+oN4TcffH\n671N9OgsSa9L+r67L5IkM5ui5An7YZIua+Lc6oWMQ5KmRHr7k+/2toe7z+p0/kEze1fJ9/btIOkv\nTZlVfZFxyMxWkPRrSccr+b7omJDx9lbIc/GWOjS3G09K+ryZDZT+9bb4NWZ2qJm9oOTLab+b/m0Z\nM7vIzF4zswXpz9PN7DP7amabm9nDZvaxmb1pZmdIsq5XHDocwMy+amZ/NrN3Oh12NLJjbpLWlvTj\nToc1jO5y2bFm9l562b+mrzp0vd5j0/382MwmhMZUy8xWMbM/mNlLZvahmb1hZteZ2RoVLvJlM7s/\nHTvdzM4N3J6rmNkV6W0538xeMLMjqpziNySN6wi+JLn7BEnvSNq7ym22OjLeXhlvN+S7jfLdpQnt\n0PHOf6U5lh0Zb6OMd3KRpOfc/foat1MGZLy9Ml7Ic/FWfUe0q3UlfSJpbqfajpI2k3SOpJmSplpy\n/PQ9kgZLOk/Ss0puyDMkrSjpREkys5WVvCI7Q9JQSfMlnSzpCz1NxMy2kvSApFeUvAI2TdIGkjZN\nh+wt6S5JTys5FEmSZqWX3ULSw5L+Luk/JH0o6SeS7rPkcKWJ6bjDJF0qabSkGyWtL+l6SfX6fM2K\nkj6WNDKd2+pKbpu/mtlG7v5xl/G3SrpK0i8k7aLk9lzcsX9m9nklhz/0T2uvpeMuN7Ol3P3/VppI\n+sBylqR13X1qWv5EyQNaV/MlbdKrPS0PMt5eGe9wbXpfzVZyv45w939UtcetjXy3Z7472z79OSXn\nPpYNGW+zjJvZtpIOVpyH5YaQ8fbKeDHPxd29ZU6ShklySV9S0iSvIOnI9Ma4tdO4qUqCs1qXyx+U\nXv5bXeqnpzfmwPT8Ben5tTqN+Zykt5Ob5DOXdUlndzr/kKQ3JC3TzX5MlXRNoD5eyX/C/TrV+qS1\nW9PzS6Tbv7vLZfdP5zK6h9twnXTc4b243ftIWiu93N6d6mentRFdxv+npDmSlk/Pn6HkH9MGgXFv\nS+rb5f5dp9OYM5V8Lm7tTrW/SXqiy7bWVvIPbn6zc0rGyXgdMr65pIsl7aHkCfpxSv4Tf7PjPizj\niXyT7wrzWyPN97hmZ5SMk/F6ZFxSP0nPSzq/y/1wft59atUTGSfjaa2Q5+KtemjuC5IWSnpXyTHI\n10o6tMuYx919RpfarkqOZ37UzPp2nJR82HZJJa/ISMmHnh939zc6Luju8yTd3t2kzGwZSdtIutbd\nP+zNDplZfyVPOG+StLjT3EzSfZK+lQ5dMz39scsmblEdFzIxs6MsWQVtbrrdjndhvhQY3nUuN0ga\noE9fEdlV0hOSXutyu9+j5MPNgyvNw93Pdfe+7v56p/JvJG1lZueb2UAz20jS1UrCH8MiFxIZb+uM\nu/vf3f0kd7/d3R9090vT61hVyQJGZUe+2zjfXeY5QNJt6RwPybd3pUDG2zvjpyh55+mC3u5XiZDx\n9s54Ic/FW/XQ3L2VvM0+R9Lrnn17WpKmB2oDlXTrCytsd6X05yBJzwX+/lYP81pByaskvV25S0re\ngu+j5BWLM0IDLDnWe1BoLu6+yMzeqeJ6Q9dzjKTfSrpEyWEQ7ynZr8clLR24SNfbpeN8x3HsA5Uc\nstDT7Z6Lu1+bBv4kJa+guZLDIu5SPIfmkvE2zniIu08ys5ckfa3WbbUA8k2+O5703S5pPUnbu3s1\nt3urIuNtmnEz+4KS5yaHS1rKzJbq9OelzGx5SXPc/ZO822xRZLxNMy4V91y8VRvR5/zTlboq8UDt\nHSXHRO9X4TJT05/Tlbzz0FVP343znpJXAapZbGF2etnfS/qf0AB3X2xmHf+oPzOX9FWNmp/spg6Q\nNN7dT+y0/XW7Gb+qpFe7nJeSwwil5HafqWQ1tZAXeztBdz/DzC5U8gRmpru/ZclqXY/0dlstioy3\neca7Ebrfy4Z8t3m+zWxJSTdLGiLp2+7+bG+30eLIePtmfD0ljcI1gb+dlJ42l/RUL7bZish4+2Zc\nUjHPxVu1Ea3W3Uq+62auu7/QzbjHJJ1sZmt1HBJgZp9T8nmtitz9QzN7RNK/m9m57v5RhaHzlRyy\n0fmy88zsYSUfap/klb9HbZqS49L3U/Kh5A77qn731zKSPuhS6+6Qqf0kXdjp/AFKPqze8cTibknH\nSPqHu8+s0xw7DtF4VpLMbFdJGylZMrqdkfF8SpHxzsxsiJLDcW5uxPZLgnzn09L5Tt9RuFbSv0n6\nnvPVC52R8XxaOeNPKVmkp6v7lTSnVypZRKddkfF8Wjnj/9Lo5+KxNaLXKrkTx5vZr5SsltVP0hcl\n7anku3A+VPKdYUoOGQAAIABJREFUT8OVfC/S2fp0pa5KYe7sJEkPSnosvY5pSl4p2Mzdj0nHTJa0\nnZl9T8lqYG97sgrVCUo+YH2PmV2p5NWglSVtIamPu49IX4k5R9J/mdl/KzkGfH1JI5QNbHe2NLPZ\ngfpYJWE91cxOU/Jh5H+T9INutvUf6ROLJ5WswHW4kg+Nv5/+/ddKPsD9sJn9WsmrLp9TEtbt3H2v\nShs2szOVfEj6ix3HppvZ5pJ2kzQpHbatkvvnl+7+aI97Hjcy/qkyZ/xaJa8YT1LyCu3mSlbOe1PJ\noTrtinx/qrT5VvJuww+VfH5unpl9o9NFpkV2iG5vkfFPlTLj7j5byYqtXcdJySGsmb+1GTL+qVJm\nPK0V81zcW2CFro6TPl3Jaf0exk1VYCWs9G9LK1lh6gUloX5XyZ12ttIVo9JxHcs3f6zkyd8ZSpaf\n9i7b+8xKXWltcyWfe5mt5B/MC5JO7fT3jdJtf6guq2tJ+rKSQM9M5zdNSSB373Idxyr5sPfHkiYo\nCcBU5V+pq9JpZSWvEF2uZLnoOZLuULIsd9dVyc5Oa5soeaXvIyX/mM+TtESX6+34UufXlKyCNjO9\nDY4L3L/rBK6jc21jJW/7d9y+kyQd0ux8knEyXseMj5T0jKT3lXye4w1JoyQNanZGyTf5rkO+p3Yz\n/7O72/9WP5FxMt7NfrniWjWXjLdxxlXQc3FLrwwAAAAAgEK06te3AAAAAAAiRSMKAAAAACgUjSgA\nAAAAoFA0ogAAAACAQtXUiJrZrmb2opm9YmYj6jUpoFWQccSOjCNm5BuxI+Mos6pXzTWzPpJekvRt\nJcsePynpQHef3M1lWKIXRXjb3VepdSNkHC2sKRkn3ygIj+GIHRlH7HJlvJZ3RLeS9Iq7v+ruC5R8\nH0/FL0sFCvR6z0NyIeNoVWQcMSPfiB0ZR+xyZbyWRnQNJV/C3mFaWgNiQcYROzKOmJFvxI6Mo9T6\nNvoKzOwISUc0+nqAZiHjiBn5RuzIOGJHxtGqamlE35S0Vqfza6a1z3D3UZJGSRyXjtIh44hdjxkn\n3ygxHsMROzKOUqvl0NwnJW1gZuuaWT9JB0gaW59pAS2BjCN2ZBwxI9+IHRlHqVX9jqi7LzKzoyXd\nI6mPpKvc/fm6zQxoMjKO2JFxxIx8I3ZkHGVX9de3VHVlHA6AYkx09yHNuGIyjoI0JePkGwXhMRyx\nI+OIXa6M13JoLgAAAAAAvUYjCgAAAAAoFI0oAAAAAKBQNKIAAAAAgELRiAIAAAAACkUjCgAAAAAo\nFI0oAAAAAKBQNKIAAAAAgELRiAIAAAAACkUjCgAAAAAoFI0oAAAAAKBQNKIAAAAAgELRiAIAAAAA\nCkUjCgAAAAAoVN9mTwAAgDJZYonsa7hbbLFFcOwtt9ySqa255pq5t/u73/0uOPbEE0/M1BYsWBAc\nC7Sje+65J1ifMWNGpjZ06NBGTwdAAO+IAgAAAAAKRSMKAAAAACgUjSgAAAAAoFA0ogAAAACAQtW0\nWJGZTZU0R9Inkha5+5B6TApoFWQcsSPjlQ0ZEr4pTjnllExtn332yb1ddw/WFy9enKkdddRRubdx\n/PHHB8d+8sknuecWIzIevy233DJTGzx4cHDs9OnTGz2dQpFvlFk9Vs3d0d3frsN2gFZFxhE7Mo7Y\nkXHEjHyjlDg0FwAAAABQqFobUZd0r5lNNLMjQgPM7Agzm2BmE2q8LqAZyDhi123GyTciQMYRM56n\noLRqPTR3W3d/08wGShpnZi+4+0OdB7j7KEmjJMnMwh+MAVoXGUfsus04+UYEyDhixvMUlFZN74i6\n+5vpz5mS/ixpq3pMCmgVZByxI+OIHRlHzMg3yqzqd0TN7HOSlnD3Oenv35F0bt1m1gKWXnrpTG31\n1VcPjj388MMzte9973vBsRtvvHHuOSyxRPa1gtDKipL0/PPPZ2rjx48Pjr3tttsytQceeCD3vNpB\nO2Qc7Y2Mf+rAAw/M1EaNGhUc279//0ZPp0fDhw/P1J577rng2Er70Q5iz/g666yTqV144YXBsQcc\ncECDZ9N4K6ywQrB+6623ZmqDBg0Kjr3lllvqOqdmij3fiF8th+auKunPZtaxnevc/e66zApoDWQc\nsSPjiB0ZR8zIN0qt6kbU3V+V9NU6zgVoKWQcsSPjiB0ZR8zIN8qOr28BAAAAABSKRhQAAAAAUChz\nL24V51ZdMnq33XYL1keMGJGpbbPNNo2ezmekx/1/Rj3us9mzZ2dqxxxzTHBs6IP9CxYsqHkODTTR\n3Yc044pbNeOITlMyHkO+Ky3kcvzxx2dqffr0CY4NPQbfcMMNwbF33HFHpnb77bcHxy633HKZ2rnn\nhtcdOeSQQzK1f/7zn8GxX/jCF4L1FsZjeBfrrbdesH733dmPA6699trBsfvss0+mduedd9Y2sYKd\ncsopwfrPf/7zTO2xxx4Ljv3Od76TqX300Ue1Taz3yHhBKi0c+sMf/jBT69evX+7tbrjhhsH6nDlz\nMrXp06cHx44cOTJTmzp1au45tLhcGecdUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCga\nUQAAAABAofo2ewKN8vWvfz1YHzVqVKY2ePDg4NjQirWVXHvttZnam2++GRx73XXX5d5urbbeeutg\n/eSTT87Urr766uDY++67L1ObNWtWbRMDmmDLLbcM1ldaaaWGXN8777yTqU2cOLEh14V8hg8fHqxX\nWiE35NVXX83UDjrooKrn1OHDDz/M1P7whz8Exx5wwAGZWv/+/YNjV1555Uzt7bff7uXs0Ew/+9nP\ngvXQarqVnrussMIKdZ1Tox111FGZ2hlnnJH78vfff3+w3oQVclFnoeewknTmmWdmagMGDGjIHJ56\n6qlgfbXVVsvUtt9+++DYvffeO1O76KKLgmPPOuusXsyuPHhHFAAAAABQKBpRAAAAAEChaEQBAAAA\nAIWiEQUAAAAAFCqKxYrWWGONTO3oo48Ojt14440ztUoL75x22mmZ2o033hgcG/rwu7sHxxbpueee\nC9anTJmSqT3wwAPBsZtvvnmmdu+999Y0L8QttHBLaMEUSTr44INruq5KC3OE/v2tu+66wbG9Wcwg\ndH2V/q3PnTs3U3vttdeCY4855phM7ZFHHsk9L+Tz0ksvBeubbbZZpjZu3Ljg2GOPPbauc+rOhAkT\ngvXQgkmh/98kaeedd87UbrjhhtomhoYJZfHAAw8Mjg09Hs2bNy84dtKkSbVNrGADBw7M1Co9Vi9e\nvDhTe/jhh+s+JxTvO9/5TqZ2/vnnB8f269cvU3v88ceDY0eOHJmpvfzyy7nnVal36Ns321pVWijs\nkksuydQqLcQU+rceWpypbHhHFAAAAABQKBpRAAAAAEChaEQBAAAAAIWiEQUAAAAAFKrHRtTMrjKz\nmWb2XKfaimY2zsxeTn+GP4ULlAAZR+zIOGJHxhEz8o1Y5Vk1d7Sk30n6n061EZLGu/uFZjYiPX9q\n/aeXz0knnZSpVVphLrTK1S677BIc+8wzz9Q2sRa2aNGi3GP//ve/Z2rLLLNMcOymm26a6/KSNH/+\n/NxzaLDRavGMt4KhQ4dmarvttltw7A9/+MNMrVGrSPdm1dxGueuuu4L10OrUgwcPDo7dY489MrU6\nrpo7WmRckrT99tsH66HHtNmzZwfHLly4sK5zarQhQ4ZkahGumjtakWT8wgsvzNRWWmml4NjQ49zv\nf//74NjJkyfXNrGCHXnkkZlaaHVcqTW+paDBRiuSfFcSWvFWks4444xMbckllwyOPffcczO10Mq0\nkvT+++/3Ynb5LViwIFP78MMPg2MPOeSQTO2NN94Ijt12221rm1iL6vEdUXd/SNK7Xcp7SRqT/j5G\n0vfrPC+gMGQcsSPjiB0ZR8zIN2JV7WdEV3X36envMyStWqf5AK2CjCN2ZByxI+OIGflG6eU5NLdb\n7u5mVvGYCDM7QtIRtV4P0CxkHLHrLuPkGzEg44gZz1NQVtW+I/qWmQ2SpPTnzEoD3X2Uuw9x9+yH\nVIDWRcYRu1wZJ98oMTKOmPE8BaVX7TuiYyUNlXRh+vO2us2owcaOHZupxbwoUSUbbrhh7rE//vGP\nM7Wvfe1rwbH7779/pnb66acHx1500UW559AEpc14SJ8+fYL1gw8+OFOrtADRvvvum/v65s2bl6nN\nnTs3OPbmm2/O1M4777zg2NBiY6haVBnPK5TN7uoxqLRQRhto6Yyvt956wfoWW2xR03ZHjhxZ0+WL\ntvPOOwfryy+/fO5tvPrqq5napEmTqp5TSbR0vnvrV7/6VbAeWqSn0mJrZ511Vl3n1GhHHXVUpjZj\nxozg2N13373R02mKPF/fcr2kxyR9ycymmdlhSkL/bTN7WdLO6XmglMg4YkfGETsyjpiRb8Sqx3dE\n3T38PSjSTnWeC9AUZByxI+OIHRlHzMg3YlXtZ0QBAAAAAKgKjSgAAAAAoFA0ogAAAACAQtX8PaKt\nYMKECbnH/uhHP8rUjj/++ODYmFca3GGHHTK166+/Pjh2wIABmVpoddxKVlxxxdxj0RiV7tt99tkn\n9zZefPHFTO3SSy8Njn3kkUcytcmTJ+e+LgD1w7+95uvfv3+mdvHFFwfH9ub/zDFjxlQ9p1Zx6qmn\nBuv9+vXLvY3LLrssU3vnnXeqnhOK9+1vfztY//jjjzO1c845p9HTqavtt98+WP/lL3+ZqU2cODE4\nNnQ7xIB3RAEAAAAAhaIRBQAAAAAUikYUAAAAAFAoGlEAAAAAQKGiWKxo7NixmdozzzwTHLvppptm\najvvvHPu7cbi0EMPzdSWX3754Nhbb70193bnzJmTqf32t7/NPzE0xL777husu3vubYQWflhrrbWC\nY9dcc81M7fOf/3xw7OOPP557DkC7+eY3vxmsb7jhhplapcVZ7rjjjrrOCb233HLLZWp77rlnzdu9\n++67a95GkdZZZ51MbaONNsp9+VmzZgXrV1xxRbVTQov74IMPMrUXXnihCTPJZ7311svUrrvuuuDY\nJZbIvh/40EMP1X1OrYx3RAEAAAAAhaIRBQAAAAAUikYUAAAAAFAoGlEAAAAAQKFoRAEAAAAAhYpi\n1dzQSq0PPPBAcGxo1dzzzjsvOHbixImZ2ptvvtm7yZXIbrvtFqxvu+22ubdx7LHHZmox32btZOut\nt85Vk6TTTjstU/vwww+DY1955ZVMbfLkycGxl1xySaYW+ncKlNGSSy6ZqZ1zzjnBsf369cvULr30\n0uDYuXPn1jYxNISZ1byNb33rW5naTTfdVPN2axXKsiQNHz48U1t99dVzb3fVVVcN1ufNm5ep7brr\nrsGx48aNy319aL7QivuVvu3ivvvua/R0/uXggw8O1i+44IJMrVLGQ891zjzzzNomVjK8IwoAAAAA\nKBSNKAAAAACgUDSiAAAAAIBC0YgCAAAAAArV42JFZnaVpO9Jmunum6S1syX9h6RZ6bDT3P2uRk2y\nGqeffnqwHlqQZ+ONNw6OveOOO3JdXpJmzJjRi9k136BBgzK1U089Nffl33nnnWD90UcfrXpOzVLW\njPdGpQ/Kh/L85S9/uSFzWGWVVYL10Af+v/KVrwTHrrbaapnaTjvtVNvE2kA7ZLxWyy23XKY2ZMiQ\n4NjDDz88U6u0GNd1112Xew6hfO+4447Bse6ee7uxK0O+33///UytUjb22GOPTG3AgAHBsUcddVSm\nFsqyJN11V3b3p0yZEhz70ksvZWofffRRcGzI4MGDg/UTTjghU+tNlhcvXhysx/7voQwZr9WsWbOC\n9S996UuZ2p133hkce/fdd2dq06ZNq21iknbfffdMba211gqO7dOnT+7t3n777Zlapf9LYpXnHdHR\nkkJLj/3a3TdLT6UNPiAyjviNFhlHvEaLfCNuo0XGEaEeG1F3f0jSuwXMBWgKMo7YkXHEjHwjdmQc\nsarlM6JHm9kzZnaVma1QaZCZHWFmE8xsQg3XBTQDGUfsesw4+UaJ8RiO2JFxlFq1jejlkr4oaTNJ\n0yX9qtJAdx/l7kPcPfxhG6A1kXHELlfGyTdKisdwxI6Mo/SqakTd/S13/8TdF0v6T0lb1XdaQHOR\nccSOjCNm5BuxI+OIQY+r5oaY2SB3n56e3VvSc/WbUn1UWt3t7LPPztQuv/zy4NhNN900U9t6662D\nYx988MFM7d13W/dw/t6sVBpy4403BuuvvPJK1XNqJWXIeG+89dZbwfro0aOLnUjAoYcemqk99dRT\nwbE77LBDpnbSSScFx1588cU1zSt2sWU8r0or4Z5zzjmZ2i677FLz9Q0dOjT3WDPL1HqzGug111yT\ne2zsWi3foeckBx10UHDsz3/+80xt+PDhwbGh1XR//OMfB8f+6Ec/6m6Kn/HYY49lavPmzQuODeW2\n0iq/jTJ37txMrdLq/rFotYzXKrRatCSNGTMmU9tzzz2DYyvVaxVa0fc3v/lNcGxoPzbYYIPg2Jtu\nuqm2iUUgz9e3XC9pB0krm9k0SWdJ2sHMNpPkkqZKOrKBcwQaiowjdmQcMSPfiB0ZR6x6bETd/cBA\n+coGzAVoCjKO2JFxxIx8I3ZkHLGqZdVcAAAAAAB6jUYUAAAAAFCoqhYrKrPQIjsvv/xycOztt9+e\nqVX6YHFokZ7LLrssOPb555/P1B599NHg2EqLLoV8/etfz9ROPvnk4NittsourlZpUYz58+dnaiwE\ng+4MHDgwU5s5c2buy1fKYm8WbgH69++fqY0bNy44dtlll83UQo99kvT2229naldccUVw7AEHHJCp\nbbzxxsGxtTr66KOD9QULFtS03Uq32UMPPVTTdhF22mmnZWpXXXVVcOx2222Xqf3Xf/1XzXOotDBj\nSK2LbPXGww8/HKwffvjhmVosiye2i9mzZwfr++67b6a26667BseGcrfNNtsEx4YWIKr0WBd6zJ8x\nY0Zw7CabbJKpVVqsaPLkycF6O+EdUQAAAABAoWhEAQAAAACFohEFAAAAABSKRhQAAAAAUCgaUQAA\nAABAodpu1dyQSZMmBet77bVXphZaSVeS1l9//UztkksuyT2HSiv3Lly4MFOrtBpdaA5LLbVU7jlU\ncsopp2Rq//jHP2reLspl9dVXz9R+97vfBceGVoGutNJyaEW8ddddt5ezQztbbrnlgvXrrrsuUwut\njiuFV9gcOXJkcOyf//zn3HNbc801M7VGrZp74oknButz587N1EKrt1dSaTVLVs0tTqUVYEP1+++/\nPzj2qKOOyn19Q4cOzdRWXnnl3Jevh8MOOyxTu/nmm4Nj582b1+jpoEkWLVqUqd1xxx25L3/nnXfW\nczp1teGGG2ZqTz/9dBNm0jy8IwoAAAAAKBSNKAAAAACgUDSiAAAAAIBC0YgCAAAAAArFYkXdmDBh\nQqZWaRGV0KJAw4cPD47de++9M7XQghaSZGaZWqXFit5///1MbcCAAcGxyyyzTKZ20003Bcdedtll\nwTray0477ZSp7bnnnsGxV199daZ2/PHHB8eeddZZmVql3E6ePDlTGzNmTHAs2seQIUOC9V122SVT\nmz9/fnDssGHDMrXHH388OLZv3+x/nT/5yU+CYw888MBgPSS04MoRRxwRHPvaa6/l3m6tixWhXKZO\nnRqsn3rqqbm30Zuxf/vb3zK1LbfcMvflr7nmmmCdx3bEbosttsjUWKwIAAAAAIAGohEFAAAAABSK\nRhQAAAAAUCgaUQAAAABAoXpsRM1sLTO738wmm9nzZnZsWl/RzMaZ2cvpzxUaP12g/sg4YkfGETPy\njdiRccQqz6q5iySd6O6TzGxZSRPNbJykYZLGu/uFZjZC0ghJ+ZdZK6mPP/44d/0Xv/hFcGyleiOc\nd955wfrIkSMztUWLFgXHVlqlNyJkPIferIJ4xRVXZGorrbRSzXMI5XnWrFk1b7cNkPHUxRdfHKyH\nVsjt379/cOzPfvazTO2CCy7IPYeFCxcG66EV1cePH597u22MfBdgt912C9ZD/zf05nnDXXfdVfWc\n2ggZR5R6fEfU3ae7+6T09zmSpkhaQ9JekjrW1h4j6fuNmiTQSGQcsSPjiBn5RuzIOGLVq8+Imtk6\nkjaX9ISkVd19evqnGZJWrevMgCYg44gdGUfMyDdiR8YRkzyH5kqSzGyApFskHefuH5jZv/7m7m5m\nweMwzOwISeFv5AZaCBlH7KrJOPlGWfAYjtiRccQm1zuiZrakkuBf6+5/Sstvmdmg9O+DJM0MXdbd\nR7n7EHcfUo8JA41AxhG7ajNOvlEGPIYjdmQcMerxHVFLXm65UtIUd7+k05/GShoq6cL0520NmSFq\nstFGGzV7Ci2PjOfz17/+NVP76U9/Ghw7cODATG3x4sXBse+9916mdsIJJwTH3nTTTd1NERWQ8U+t\nttpqwfqoUaMytT322CM4dpVVVsl9fVOnTs11XRILE1WLfBfjzDPPrHkbkyZNytRYrKhnZDxOM2cG\nXzdoK3kOzd1G0kGSnjWzp9LaaUpC/0czO0zS65L2a8wUgYYj44gdGUfMyDdiR8YRpR4bUXd/RJJV\n+PNO9Z0OUDwyjtiRccSMfCN2ZByx6tWquQAAAAAA1IpGFAAAAABQKBpRAAAAAEChcn+PKMppl112\nyT124sSJDZwJyi60Yu2RRx4ZHLvSSitlapVWhxs2bFimNn369OxAoIJZs2YF63PmzMnUDjvssIbM\n4emnnw7WDznkkEztmWeeacgcgEZae+21a97Gww8/nKmF/p0C7eAvf/lLs6fQdLwjCgAAAAAoFI0o\nAAAAAKBQNKIAAAAAgELRiAIAAAAACsViRRHZdtttM7V+/frlvvxjjz1Wz+mgDey8887NngJQcfGf\n/fffP1MbO3ZscGzfvtn/Dl966aXg2B/84AeZ2htvvBEcy0IsiMWECROC9e9+97uZ2uTJk4NjR44c\nWdc5Ac2y/PLLB+vbbbddpjZlypTg2IULF9Z1TmXEO6IAAAAAgELRiAIAAAAACkUjCgAAAAAoFI0o\nAAAAAKBQNKIAAAAAgEKxam5E+vfvn6mZWe7LH3300cH6+++/n6m98MIL+ScGAE1w7733ZmpLL710\nE2YClN+ee+7Z7CkALWOTTTYJ1kPPxV988cXg2EWLFtV1TmXEO6IAAAAAgELRiAIAAAAACkUjCgAA\nAAAoVI+NqJmtZWb3m9lkM3vezI5N62eb2Ztm9lR62r3x0wXqj4wjZuQbsSPjiB0ZR6zyLFa0SNKJ\n7j7JzJaVNNHMxqV/+7W7X9y46aE3xo0bl6kNGzYsOPZrX/taprb//vsHx952222ZWmSLFZFxxIx8\nI3ZkHLEj4y1ms802yz32f//3fxs4k3LrsRF19+mSpqe/zzGzKZLWaPTEgKKQccSMfCN2ZByxI+OI\nVa8+I2pm60jaXNITaeloM3vGzK4ysxXqPDegcGQcMSPfiB0ZR+zIOGKSuxE1swGSbpF0nLt/IOly\nSV+UtJmSV2l+VeFyR5jZBDObUIf5Ag1DxhEz8o3YkXHEjowjNrkaUTNbUknwr3X3P0mSu7/l7p+4\n+2JJ/ylpq9Bl3X2Uuw9x9yH1mjRQb2QcMSPfiB0ZR+zIOGKUZ9Vck3SlpCnufkmn+qBOw/aW9Fz9\npwc0HhlHzMg3YkfGETsyjliZu3c/wGxbSQ9LelbS4rR8mqQDlRwK4JKmSjoy/TB1d9vq/sqA+pjY\nm1f9yDhKKHfGyTdKiMdwxI6Ml9zRRx8drB977LGZ2gYbbNDo6bSiXBnPs2ruI5Is8Ke7qpkV0GrI\nOGJGvhE7Mo7YkXHEqler5gIAAAAAUCsaUQAAAABAoWhEAQAAAACF6nGxorpeGR+QRjF6tQhAPZFx\nFKQpGSffKAiP4YgdGUfscmWcd0QBAAAAAIWiEQUAAAAAFIpGFAAAAABQKBpRAAAAAEChaEQBAAAA\nAIXqW/D1vS3p9fT3ldPzMWLfmmvtJl53R8bLcDtVi31rvmZlnMfw8ivDvrXCY7hUjtuqWuxbc5Hx\nxmPfmitXxgv9+pbPXLHZhGYtXd1o7Btivp3YN0hx31bsG6S4byv2DVLctxX7Vg4cmgsAAAAAKBSN\nKAAAAACgUM1sREc18bobjX1DzLcT+wYp7tuKfYMU923FvkGK+7Zi30qgaZ8RBQAAAAC0Jw7NBQAA\nAAAUqvBG1Mx2NbMXzewVMxtR9PXXk5ldZWYzzey5TrUVzWycmb2c/lyhmXOslpmtZWb3m9lkM3ve\nzI5N61HsXyOR8XIg49Uj4+VAxqsTU76leDNOvqsXU8ZjzbfUHhkvtBE1sz6Sfi9pN0mDJR1oZoOL\nnEOdjZa0a5faCEnj3X0DSePT82W0SNKJ7j5Y0jck/TS9r2LZv4Yg46VCxqtAxkuFjPdShPmW4s04\n+a5ChBkfrTjzLbVBxot+R3QrSa+4+6vuvkDSDZL2KngOdePuD0l6t0t5L0lj0t/HSPp+oZOqE3ef\n7u6T0t/nSJoiaQ1Fsn8NRMZLgoxXjYyXBBmvSlT5luLNOPmuWlQZjzXfUntkvOhGdA1Jb3Q6Py2t\nxWRVd5+e/j5D0qrNnEw9mNk6kjaX9IQi3L86I+MlRMZ7hYyXEBnPrR3yLUWWAfLdK+2Q8egyEGvG\nWayogTxZkrjUyxKb2QBJt0g6zt0/6Py3GPYPtYkhA2Qc3YkhA2Qc3Sl7Bsg3uhNDBmLOeNGN6JuS\n1up0fs20FpO3zGyQJKU/ZzZ5PlUzsyWVBP9ad/9TWo5m/xqEjJcIGa8KGS8RMt5r7ZBvKZIMkO+q\ntEPGo8lA7BkvuhF9UtIGZraumfWTdICksQXPodHGShqa/j5U0m1NnEvVzMwkXSlpirtf0ulPUexf\nA5HxkiDjVSPjJUHGq9IO+ZYiyAD5rlo7ZDyKDLRDxi15R7fAKzTbXdKlkvpIusrdLyh0AnVkZtdL\n2kHSypLeknSWpFsl/VHSFyS9Lmk/d+/6IeqWZ2bbSnpY0rOSFqfl05Qcm176/WskMl4OZLx6ZLwc\nyHh1Ysquj6WuAAAAYklEQVS3FG/GyXf1Ysp4rPmW2iPjhTeiAAAAAID2xmJFAAAAAIBC0YgCAAAA\nAApFIwoAAAAAKBSNKAAAAACgUDSiAAAAAIBC0YgCAAAAAApFIwoAAAAAKBSNKAAAAACgUP8/ucXx\nZIHc2oEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1191e3b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize = (16, 10))\n",
    "plt.suptitle(\"10 examples classified using \" + model_name,\n",
    "             fontsize = 25)\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        sample = mnist.test.next_batch(1)\n",
    "        image = sample[0].reshape(rows, cols)\n",
    "        label = sample[1]\n",
    "        pred_label = model.predict(image.reshape(-1, rows, cols, 1))\n",
    "        label = np.argmax(label)\n",
    "        pred_label = np.argmax(pred_label)\n",
    "        ax[i][j].imshow(image, cmap = 'gray')\n",
    "        ax[i][j].set_title(\"Correct Label:\" + str(label) +\n",
    "                           \"\\nPredicted Label:\" + str(pred_label),\n",
    "                           fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Keras Implementation) Softmax Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 789\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/18\n",
      "54700/55000 [============================>.] - ETA: 0s - loss: 0.5391 - acc: 0.8424Epoch 00000: val_loss improved from inf to 0.26226, saving model to saved_models/softmax_mlp_model.h5\n",
      "55000/55000 [==============================] - 12s - loss: 0.5376 - acc: 0.8428 - val_loss: 0.2623 - val_acc: 0.9246\n",
      "Epoch 2/18\n",
      "54750/55000 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9329Epoch 00001: val_loss improved from 0.26226 to 0.19561, saving model to saved_models/softmax_mlp_model.h5\n",
      "55000/55000 [==============================] - 12s - loss: 0.2371 - acc: 0.9329 - val_loss: 0.1956 - val_acc: 0.9436\n",
      "Epoch 3/18\n",
      "54850/55000 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9483Epoch 00002: val_loss improved from 0.19561 to 0.16255, saving model to saved_models/softmax_mlp_model.h5\n",
      "55000/55000 [==============================] - 11s - loss: 0.1835 - acc: 0.9482 - val_loss: 0.1626 - val_acc: 0.9542\n",
      "Epoch 4/18\n",
      "54750/55000 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9582Epoch 00003: val_loss improved from 0.16255 to 0.13912, saving model to saved_models/softmax_mlp_model.h5\n",
      "55000/55000 [==============================] - 12s - loss: 0.1506 - acc: 0.9581 - val_loss: 0.1391 - val_acc: 0.9622\n",
      "Epoch 5/18\n",
      "54800/55000 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9648Epoch 00004: val_loss improved from 0.13912 to 0.12393, saving model to saved_models/softmax_mlp_model.h5\n",
      "55000/55000 [==============================] - 11s - loss: 0.1269 - acc: 0.9648 - val_loss: 0.1239 - val_acc: 0.9644\n",
      "Epoch 6/18\n",
      "15550/55000 [=======>......................] - ETA: 7s - loss: 0.1124 - acc: 0.9702"
     ]
    }
   ],
   "source": [
    "# Directory and filename for saving the best model\n",
    "save_dir = \"saved_models/\"\n",
    "model_name = \"softmax_mlp\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "modelpath = os.path.join(save_dir, model_name + \"_model.h5\")\n",
    "\n",
    "# Optimization parameters for learning like learning rate,\n",
    "# batch size, epochs\n",
    "lr = 1e-4\n",
    "batch_size = 50\n",
    "epochs = 18\n",
    "seed = np.random.randint(1000)\n",
    "print(\"Seed: %d\" %seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Weight initializer based on normal distrubution of \n",
    "# mean 0, stddev 0.1 used for the layers\n",
    "weight_init = keras.initializers.RandomNormal(stddev = 0.1,\n",
    "                                              seed = seed)\n",
    "# Bias initializer to a constant 0.1 value used for the layers\n",
    "bias_init = keras.initializers.Constant(value = 0.1)\n",
    "\n",
    "# Specify input shape (doesn't change from before)\n",
    "inputs = Input(shape = input_shape)\n",
    "\n",
    "# Flatten input to a vector since this is an MLP\n",
    "x = Flatten()(inputs)\n",
    "# 512 fully connected units with ReLU activation\n",
    "x = Dense(512, activation = 'relu', \n",
    "          kernel_initializer = weight_init,\n",
    "          bias_initializer = bias_init)(x)\n",
    "# Output layer with units equal to the number of classes\n",
    "# Uses softmax activation for probability distribution\n",
    "outputs = Dense(num_classes, activation = 'softmax',\n",
    "          kernel_initializer = weight_init,\n",
    "          bias_initializer = bias_init)(x)\n",
    "# Define model\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "# Compile model by specifying loss and optimizer\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr = lr),\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Define log callback for tensorboard\n",
    "tensorboard = TensorBoard(log_dir = './logs', batch_size = batch_size)\n",
    "\n",
    "# Define callback for saving the best model\n",
    "checkpoint = ModelCheckpoint(filepath = modelpath,\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True)\n",
    "\n",
    "callbacks = [tensorboard, checkpoint]\n",
    "\n",
    "# Fit training data and use validation loss for checkpoints\n",
    "model.fit(train_data, train_labels,\n",
    "          batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (val_data, val_labels),\n",
    "          shuffle = True, callbacks = callbacks)\n",
    "\n",
    "# Evaluate data on the test set\n",
    "score = model.evaluate(test_data, test_labels, verbose = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize = (16, 10))\n",
    "plt.suptitle(\"10 examples classified using \" + model_name,\n",
    "             fontsize = 25)\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        sample = mnist.test.next_batch(1)\n",
    "        image = sample[0].reshape(rows, cols)\n",
    "        label = sample[1]\n",
    "        pred_label = model.predict(image.reshape(-1, rows, cols, 1))\n",
    "        label = np.argmax(label)\n",
    "        pred_label = np.argmax(pred_label)\n",
    "        ax[i][j].imshow(image, cmap = 'gray')\n",
    "        ax[i][j].set_title(\"Correct Label:\" + str(label) +\n",
    "                           \"\\nPredicted Label:\" + str(pred_label),\n",
    "                           fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Keras Implementation) Simple CNN: LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 122\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_72 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_58 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 0, training accuracy: 0.06\n",
      "50/50 [==============================] - 0s     : \n",
      "\n",
      "Step 1000, training accuracy: 0.94\n",
      "5000/5000 [==============================] - 7s     \n"
     ]
    }
   ],
   "source": [
    "# Directory and filename for saving the best model\n",
    "save_dir = \"saved_models/\"\n",
    "model_name = \"simple_cnn\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "modelpath = os.path.join(save_dir, model_name + \"_model.h5\")\n",
    "\n",
    "lr = 1e-4\n",
    "batch_size = 50\n",
    "input_shape = (rows, cols, channels)\n",
    "\n",
    "seed = np.random.randint(1000)\n",
    "print(\"Seed: %d\" %seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "weight_init = keras.initializers.RandomNormal(stddev = 0.1,\n",
    "                                              seed = seed)\n",
    "bias_init = keras.initializers.Constant(value = 0.1)\n",
    "\n",
    "inputs = Input(shape = input_shape)\n",
    "x = Conv2D(32, kernel_size = 5, padding = 'same',\n",
    "           kernel_initializer = weight_init,\n",
    "           bias_initializer = bias_init)(inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2,\n",
    "                 padding='same')(x)\n",
    "x = Conv2D(64, kernel_size = 5, padding = 'same',\n",
    "           kernel_initializer = weight_init,\n",
    "           bias_initializer = bias_init)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2,\n",
    "                 padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu', \n",
    "          kernel_initializer = weight_init,\n",
    "          bias_initializer = bias_init)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(num_classes, activation = 'softmax',\n",
    "          kernel_initializer = weight_init,\n",
    "          bias_initializer = bias_init)(x)\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr = lr),\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = './logs', batch_size = batch_size)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = modelpath,\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True)\n",
    "\n",
    "callbacks = [tensorboard, checkpoint]\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (val_data, val_labels),\n",
    "          shuffle = True, callbacks = callbacks)\n",
    "\n",
    "score = model.evaluate(test_data, test_labels, verbose = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = mnist.test.images.reshape(-1, rows, cols, 1)\n",
    "test_labels = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"saved_models/\"\n",
    "model_name = \"softmax_regr\"\n",
    "modelpath = os.path.join(save_dir, model_name + \"_model.h5\")\n",
    "\n",
    "model = load_model(modelpath)\n",
    "score = model.evaluate(test_data, test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"saved_models/\"\n",
    "model_name = \"softmax_mlp\"\n",
    "modelpath = os.path.join(save_dir, model_name + \"_model.h5\")\n",
    "\n",
    "model = load_model(modelpath)\n",
    "score = model.evaluate(test_data, test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"saved_models/\"\n",
    "model_name = \"simple_cnn\"\n",
    "modelpath = os.path.join(save_dir, model_name + \"_model.h5\")\n",
    "\n",
    "model = load_model(modelpath)\n",
    "score = model.evaluate(test_data, test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
