{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision:  Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Science: COMS W 4995 006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due: March 20, 2018\n",
    "\n",
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we provide three networks for classifying handwritten digits from the MNIST dataset. The networks are implemented and tested using the Tensorflow framework. The third and final network is a convolutional neural network (CNN aka ConvNet) which achieves 99.25% accuracy on this dataset. \n",
    "\n",
    "Your task is to re-implement all three networks using the Keras wrapper around Tensorflow OR\n",
    "re-implement using Pytorch. You will likely find several Keras or Pytorch implementations on the internet. It is ok to study these. However, you must not cut and paste this code into your assignment--you must write this yourself. Furthermore, you need to comment every line of code and succintly explain what it is doing! \n",
    "\n",
    "Here is what is required:\n",
    "\n",
    "a) A FULLY commented re-implementation of the ConvNet below using the Keras wrapper on Tensorflow OR Pytorch.\n",
    "\n",
    "b) your network trained on the same MNIST data as used here.\n",
    "\n",
    "c) an evaluation of the accuracy on the MNIST test set.\n",
    "\n",
    "d) plots of 10 randomly selected digits from the test set along with the correct label and the assigned label.\n",
    "\n",
    "e) have your training record a log of the data using the Keras API and then use Tensorboard (a command line tool) to display plots of the validation loss and validation accuracy. you can zip up a screenshot of this with your notebook before submission.\n",
    "\n",
    "f) have your training continually save the best model so far (as determined by the validation loss) using the Keras API or Pytorch.\n",
    "\n",
    "g) after training, load the saved weights using the best model so far. re-run you accuracy evaluation using these saved weights.\n",
    "\n",
    "Below we include the Tensorflow examples shown in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Convolutional Neural Network in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers a python and tensorflow-based solution to the handwritten digits recognition problem. It is based on tensorflow tutorials and Yann LeCun's early work on CNN's. This toturial compares a simple softmax regressor, a multi-layer perceptron (MLP), and a simple convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the MNIST digit dataset directly from tensorflow examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import tensorflow and begin an interactive session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression Model on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create placeholders for the data. Data will be dumped here when it is batched from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what this data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABg5JREFUeJzt3UuIlWUcx/E53qYGNS0mu5iOkhpURJQWCBpJBa6UsiBp\nEW2iBAldtGsZLQ0jFEMsaBNtuxgRXVALLZK0sguljeWVYLxgOnNatHHzPjQz75zxnN/ns/37On/h\nfHkWj++ZRrPZ7ALyTBjvBYDxIX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4INamVP+yhCWv8d0IYYx8N\nvdP4P3/OyQ+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+h\nxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hWvoruqGVLj58b+Xs9G1Tis/O\nenVX3etccZz8EEr8EEr8EEr8EEr8EEr8EEr8EMo9f7hGd3dx3rxwoUWb1O/3pwYrZ/O3nm/hJlcm\nJz+EEj+EEj+EEj+EEj+EEj+EEj+Ecs/f4Sb29hbnfe8NFOe/LK5zm3pNmt9XnC+afaxyNrTnZPHZ\n5kgWajNOfgglfgglfgglfgglfgglfgjlqq/Dff/y3OL8rzcmF+e9XbvrXKdWBzdeX5xf9Un1x3vO\nxaN1r9N2nPwQSvwQSvwQSvwQSvwQSvwQSvwQyj1/Byi9trtp+dvFZ7e89EBxfmkkC9WkMan88Vy/\nfGdx/uH9t1TOhka0UWdx8kMo8UMo8UMo8UMo8UMo8UMo8UMo9/wd4M81Cypn6z+eV3x2Yf9Xda9T\nm/4XlhTn27eWn79hYFeN23QeJz+EEj+EEj+EEj+EEj+EEj+EEj+Ecs/fAc4uO1M56/l2ags3GZ7G\n5CnF+fLH9xXnv66cXpwPDnujLE5+CCV+CCV+CCV+CCV+CCV+CCV+COWevw1MnF6+z9625M3K2Ssb\nVhafHc/v5T/95D3F+ftfNIvzW0/sqXOdOE5+CCV+CCV+CCV+CCV+CCV+COWqrw00eq4uzjcfXVE5\nu9R/tO51ajPQ1yjOZx5o0SKhnPwQSvwQSvwQSvwQSvwQSvwQSvwQyj1/Gzj9YPnXbP905HzlbF7X\nqbrXqc2jqz8vzr9ZVf53j+fryJ3AyQ+hxA+hxA+hxA+hxA+hxA+hxA+h3PO3gZN3ld97n/ZZT4s2\nGb6Jty+qnK2dsb347NcDvXWvw2Wc/BBK/BBK/BBK/BBK/BBK/BBK/BDKPX8buHvpoeL88P4FLdpk\n+P545LrK2aovny0+23dqf93rcBknP4QSP4QSP4QSP4QSP4QSP4QSP4Ryz98GFs/4rTjfv7D6nflr\nRvmzG93dxfmhLXcU528t21w5e27TuhHtRD2c/BBK/BBK/BBK/BBK/BBK/BDKVV8HuNTTHPGzZx+7\nrzhftPFAcX58x5Ti/LUFKypns/aeKz7L2HLyQyjxQyjxQyjxQyjxQyjxQyjxQyj3/G3g05MLi/Of\n175eOTv8xJnisy8emVmc9z8/tzjv3be7OF+y7u/K2c5D5Y/fYHHKaDn5IZT4IZT4IZT4IZT4IZT4\nIZT4IZR7/jYwuK78BdzzNjxTObvxg8nFZ6e/u7c4b14qv88/qW9Ocd4z4XjlbPDEieKzjC0nP4QS\nP4QSP4QSP4QSP4QSP4QSP4Ryz98Ghr77oThf+PTI/+6Rf+P/f/6ZfW1xfm6o/L3+jB8nP4QSP4QS\nP4QSP4QSP4QSP4Ry1ceoHFvSU5xv+3Fp5ezmrvLrwowtJz+EEj+EEj+EEj+EEj+EEj+EEj+Ecs/P\nqAzceaE4bxyZ1qJNGC4nP4QSP4QSP4QSP4QSP4QSP4QSP4Ryz8+oTJ1xvjiftWO0Xw7OWHHyQyjx\nQyjxQyjxQyjxQyjxQyjxQyj3/IzKTasPjvcKjJCTH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJ\nH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJ\nH0KJH0I1ms3meO8AjAMnP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4QS\nP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4QSP4T6FzzCoNne+MNFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dae8ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113a93fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP4QSP4T6GwsTyHDheMttAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113c36bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113ccc2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i in range(4):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first going to do softmax logistic regression. This is a linear layer followed by softmax. Note there are NO hidden layers here. Also note that the digit images (28x28 grayscale images) are reshaped into a 784 element vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the parameters (weights) for our linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use tensorflows initializer to initialize these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our linear layer as a function of the input and the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_regressor = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create our loss function. Note that the cross entropy is $ H_{\\hat{y}}(y) = -\\sum_i \\hat{y}_{i} \\, \\log(y_{i})$ where $\\hat{y}$ is the true probability distribution and is expressed as a one-hot vector, $y$ is the estimated probability distribution, and $i$ indexes elements of these two vectors. Also note that this reduces to $ H_{\\hat{y}}(y) = -\\, \\log(y_{i^*})$ where $i^*$ is the correct label. And if we sum this over all of our samples indexed by $j$, then $H_{\\hat{y}}(y) = -\\sum_j  \\log(y^{(j)}_{i^*})$. This is precisely the same loss function as we used before, but we called the MLE loss. They are one and the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_regressor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tell tf to use gradient descent with a step size of 0.5 and to minimize the cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train by grabbing mini-batches with 100 samples each and pushing these through the network to update our weights (W and b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "  batch = mnist.train.next_batch(100)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define how to compute correct predicitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_regressor,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from these correct predictions how to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9192\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out some test images and the corresponsing predictions made by the network. But first, let's add an output to the computation graph that computes the softmax probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_regressor = tf.nn.softmax(logits=y_regressor, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12772b290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  1.67203823e-03   6.03468334e-06   6.42732251e-03   1.87764294e-04\n",
      "    9.26438749e-01   4.59894276e-04   3.28759407e-03   1.33758076e-02\n",
      "    5.87336766e-03   4.22714762e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABXBJREFUeJzt3c+r5WUdwPF77sw0MFig5AhOWJGaI24UrpDYImGSskjE\noZX9AS3Ulbh0IahbUYSyXYTgToQWI6jgookZSiEkKwzSwFKy/Hln7r2nv+A8V87h3Dv3vF+v7ed8\nn+/ZvPksnvtjMp1O14Ce9f3+AsD+ED9EiR+ixA9R4oco8UOU+CFK/BAlfog6vJcvO7V+2o8TwpKd\n2Xl+8kU+Z/NDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6IO7/cXYLV9+LPvzJydffyZ4bM3Pv3z4fyaJ34/nE+3tobzOpsfosQPUeKHKPFDlPghSvwQJX6I\nmkyn0z172an103v3MvbE4RNXD+cPvHpm5uz7xy4u9O4ffPu7w/nORx8tdP5BdWbn+ckX+ZzND1Hi\nhyjxQ5T4IUr8ECV+iPIrvSzkX3d+fThf5DrvlnM/Hc6v/Pituc/G5ocs8UOU+CFK/BAlfogSP0SJ\nH6Lc8zO0fuzYcH7n/a8t7d1Hn7t8/IE9/HX0VWTzQ5T4IUr8ECV+iBI/RIkfosQPUe75Gdq87eRw\n/ujxX8199qc7F4bzr/zmd3Ofze5sfogSP0SJH6LED1HihyjxQ5T4Ico9P0Nv33NoaWff+5e7d/nE\nP5f2bmx+yBI/RIkfosQPUeKHKPFDlPghyj0/Q3dtvL7Q8//d+Wzm7OIjVw2fXXfPv1Q2P0SJH6LE\nD1HihyjxQ5T4IcpVX9zmDzeG86dO/HKh89/Zmj1bf/UPC53NYmx+iBI/RIkfosQPUeKHKPFDlPgh\nyj1/3HsbR5Z6/o9ffHDm7Lq1s0t9N2M2P0SJH6LED1HihyjxQ5T4IUr8EOWeP+5LN/9noeffvPDp\ncH7Dk+/PnG0v9GYWZfNDlPghSvwQJX6IEj9EiR+ixA9R7vlX3Oc/unU4P7fxzC4nHBpO/3zx+HC+\n/dbfdjmf/WLzQ5T4IUr8ECV+iBI/RIkfosQPUe75V9xnXx3f0x+ZjOe7eej8PcP5N9feWOh8lsfm\nhyjxQ5T4IUr8ECV+iBI/RLnqW3Gbd3+40PO7/Wnurz273H/xzfLY/BAlfogSP0SJH6LED1Hihyjx\nQ5R7/hVw6PpvzZyd2/j1bk8Pp7/9+Kbh/MhL53c5n0uVzQ9R4oco8UOU+CFK/BAlfogSP0S5518B\n731v9r/JXvRPcz/18qnh/Lq1swudz/6x+SFK/BAlfogSP0SJH6LED1Hihyj3/Cvg8ysmcz97fvPC\ncH7yiXeG862538x+s/khSvwQJX6IEj9EiR+ixA9RrvpWwPE73p372Rf+d/Nwvv3v9+c+m0ubzQ9R\n4oco8UOU+CFK/BAlfogSP0S55z8AJkePDuc/ufr1uc/+4MJlw/l0c3Pus7m02fwQJX6IEj9EiR+i\nxA9R4oco8UOUe/6DYHt7OP7Fm7fPnD1429+Hz77yj2uH8xNrfxrOObhsfogSP0SJH6LED1Hihyjx\nQ5T4Ico9/wEw3Rr/I+xvPPzJzNnJx+4bPjv545fn+k4cfDY/RIkfosQPUeKHKPFDlPghSvwQ5Z5/\nBWz/9e2Zs2tO7+EX4UCx+SFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKH\nKPFDlPghSvwQJX6IEj9EiR+ixA9Rk+l0ut/fAdgHNj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQ9X8Tl4ztsCYvaQAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11058bad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  9.20873049e-07   9.87897158e-01   2.22241855e-03   1.86755520e-03\n",
      "    3.91291178e-05   9.39880556e-05   3.30834628e-05   3.73039884e-03\n",
      "    3.64026078e-03   4.75243636e-04]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJX4IJX4IJX4IJX4I9QkUIOmQAHIDdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed9c910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  5.94127778e-06   1.63856862e-06   2.03961849e-06   2.16156419e-04\n",
      "    9.74607527e-01   5.81776584e-03   5.42712551e-05   1.18222029e-03\n",
      "    1.06608802e-02   7.45144626e-03]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkX9GlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed6d950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Class probabilities =  [[  1.32794867e-06   3.03926598e-03   1.02855719e-03   3.06596723e-03\n",
      "    1.28692212e-02   9.07216594e-03   2.42878319e-04   1.96316512e-03\n",
      "    6.66321721e-03   9.62054253e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKPFDKPFDKPFDKPFDKPFDqP8AIYYF0tDQzC4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11edb4c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  8.77247099e-03   5.61122533e-06   5.13427751e-03   1.86741403e-07\n",
      "    6.87260833e-03   3.76259210e-03   9.73673403e-01   4.59226328e-07\n",
      "    1.65836595e-03   1.20098288e-04]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print \"Label = \", label\n",
    "    print \"Class probabilities = \", y_probs_regressor.eval(feed_dict={\n",
    "        x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Multi-Layer Perceptron on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define both weight and bias variables and how they are to be initialized. Note that the weights are are distributed according to a standard normal distribution (mean = 0, std = 0.1). This random initialization helps avoid hidden units get stuck together, as units that start with the same value will be updated identically in the non-convolutional layers. In contrast, the bias variables are set to a small positive number--this is help prevent hidden units from starting out and getting stuck in the zero part of the ReLU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create placeholders for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the first and only fully connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_h = weight_variable([784, 512])\n",
    "b_h = bias_variable([512])\n",
    "h = tf.nn.relu(tf.matmul(x, W_h) + b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_out = weight_variable([512, 10])\n",
    "b_out = bias_variable([10])\n",
    "y_MLP = tf.matmul(h, W_out) + b_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again use cross entropy loss on a softmax distribution on the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we choose an Adam learning rate and update rule. We then run this for 20,000 iterations and evaluate our accuracy after training. Note this softmax MLP network does quite a bit bettter than our softmax regressor. The non-linear layer really helps makes sense of the data! But we can do better still..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.2\n",
      "step 1000, training accuracy 0.9\n",
      "step 2000, training accuracy 0.9\n",
      "step 3000, training accuracy 0.98\n",
      "step 4000, training accuracy 0.98\n",
      "step 5000, training accuracy 0.94\n",
      "step 6000, training accuracy 0.96\n",
      "step 7000, training accuracy 1\n",
      "step 8000, training accuracy 0.96\n",
      "step 9000, training accuracy 1\n",
      "step 10000, training accuracy 0.98\n",
      "step 11000, training accuracy 1\n",
      "step 12000, training accuracy 0.94\n",
      "step 13000, training accuracy 0.98\n",
      "step 14000, training accuracy 1\n",
      "step 15000, training accuracy 0.96\n",
      "step 16000, training accuracy 0.96\n",
      "step 17000, training accuracy 0.98\n",
      "step 18000, training accuracy 1\n",
      "step 19000, training accuracy 0.96\n",
      "test accuracy 0.9779\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_MLP,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%1000 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1]})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Convolutional Neural Network: LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make our first CNN. It's quite simple network, but it's surprisingly good at this handwritten digit recognition task. This a variant on Yann LeCun's CNN network that really helped to move deep learning forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define both weight and bias variables and how they are to be initialized. Note that the weights are are distributed according to a standard normal distribution (mean = 0, std = 0.1). This random initialization helps avoid hidden units get stuck together, as units that start with the same value will be updated identically in the non-convolutional layers. In contrast, the bias variables are set to a small positive number--this is help prevent hidden units from starting out and getting stuck in the zero part of the ReLu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define how the convolution is to be computed and the extent and type of pooling. The convolution will use a 5x5 kernel and will pad the image with zeros around the edges and use a stride of 1 pixel so that the resulting image (after convolution) has the same size as the original input image. The network will learn the weights for a stack of 32 separate kernels along with 32 bias variables. Finally, after the ReLu is performed the result will be under go 2x2 max pooling, thus halfing both dimensions of the image. The choices for the stride, padding, and pooling are not parameters that the network needs to estimate. Rather these are termed \"hyperparamters\" that are usually set by the network designer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the weight and bias variables for the first convolutional layer as described above. Note the output has depth 32, so there will be 32 feature images after this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike for our softmax regressor above, here we need keep the images as images and not collapse these into vectors; this allows us to perform the 2D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define are first layer of our CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And wasting no time, we define are second layer. The second layer will have to process 32 feature images coming out of the first layer. Note that the images input to this layer have $\\frac{1}{4}$ the number of pixels as the original input images due to the 2x2 pooling in the previous layer. Note that convolution layer NOT fully connected as our previous hidden layers have been. A unit in the output layer has a limited \"receptive field.\" Its connections to the input layer are spatially limited by the kernel (or filter) size. Also, because of weight sharing in convolutional layers, the number of parameters for a convolutional is the size of the kernel x the depth of the input layer x depth of the output layer + depth of the output layer. So for the second layer of our ConvNet, we have 5 x 5 x 32 x 64 + 64 = 51,264 parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pooling stage of our second convolutional layer, we have 64 7x7 \"feature\" images. In one penultimate fully connected hidden layer, we are going to map these feature imges to a 1024 dimensional feature space. Note we need to flatten these feature images to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is added here, although it is not really needed for such small network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a final linear output layer mapping features to scores topped off with a softmax cross entropy loss function, as explained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we choose an Adam learning rate and update rule. We then run this for 20,000 iterations and evaluate our accuracy after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.16\n",
      "step 1000, training accuracy 0.94\n",
      "step 2000, training accuracy 1\n",
      "step 3000, training accuracy 0.98\n",
      "step 4000, training accuracy 1\n",
      "step 5000, training accuracy 0.96\n",
      "step 6000, training accuracy 0.98\n",
      "step 7000, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 9000, training accuracy 0.98\n",
      "step 10000, training accuracy 1\n",
      "step 11000, training accuracy 1\n",
      "step 12000, training accuracy 1\n",
      "step 13000, training accuracy 1\n",
      "step 14000, training accuracy 1\n",
      "step 15000, training accuracy 1\n",
      "step 16000, training accuracy 1\n",
      "step 17000, training accuracy 1\n",
      "step 18000, training accuracy 1\n",
      "step 19000, training accuracy 1\n",
      "test accuracy 0.9925\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%1000 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an output to compuational graph that computes the label probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_probs = tf.nn.softmax(logits=y_conv, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9925\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we step through some test examples and see how well the network is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4odQ4odQ/wPLax9UR54iwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d599f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Class probabilities =  [[  5.28820287e-14   1.61565119e-12   1.47112888e-12   1.99402633e-10\n",
      "    8.20477112e-07   1.07506337e-09   4.57562201e-15   8.61227306e-07\n",
      "    3.80472631e-09   9.99998331e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABwxJREFUeJzt3V1s3XUdx/HT0610sK1dhhgSXFzGwwaC8yEmChqH7EKj\naGJqSJSMwIVmGJcZSTTihTFOjHpBfEjQGLngYs00mDAU0wQzNBuMscAIqFvMSBzGMZlTsg3pw/HS\nq//3dOXsrO3n9br99H/Of2nf+V/81p6BTqfTAvK0L/QNABeG+CGU+CGU+CGU+CGU+CGU+CGU+CGU\n+CHUkn6+2eb2mP9OCOfZxMyugdl8nSc/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/\nhBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hOrr\nR3Rzfrz+ifc1bst+e7C8tvPea8v96K2XlPsHb36+3P/w+PXlXrl833S5Dz+yf86vjSc/xBI/hBI/\nhBI/hBI/hBI/hBI/hBrodDp9e7PN7bH+vdkCMnjp6nKfHl9W7g9etbNxOz69tLx2pD1Z7muWXFzu\n59Mr02fK/e/TQ+X++R3bGrfVP9s3p3taCCZmdg3M5us8+SGU+CGU+CGU+CGU+CGU+CGU+CGU3+ef\nBw7fv6bc/7L+511eofks/rLB+sqfnLq63A++Vt/bsdOj9RsUBgdmyv3Rax4p927/tvF7v9e4feFP\nXyyvbf/x2frFFwFPfgglfgglfgglfgglfgglfgjlqK8POu9/Z7mPf+CBLq9Qf5seO9t81HffPVvK\na1e88M/6rU+cLOf2v/5WX1/otOuzuqt/sLXcX/zMD8t93dLljdvZe/9TXjtyx1vLfeofx8t9IfDk\nh1Dih1Dih1Dih1Dih1Dih1Dih1DO+ftgcqT+E9Mbh+pvw0yr/ovn9/zizsbtbQ/vLa+tPwT7PJup\n3/3K7U+W+4ah+tdyD33y/sZtz/W/LK+98Zb6/xiMPOScH1igxA+hxA+hxA+hxA+hxA+hxA+hnPP3\nwfTwrD4xudENe+8o9zXfrs/yF6ur7n6q3HffcnnjNrb81fLaU7eeLveRh8p5QfDkh1Dih1Dih1Di\nh1Dih1Dih1Dih1DO+fvgmq+98KauH3xmRY/uJMvXn/5U4za2qf7Y87uve6Lcd7dWzeme5hNPfggl\nfgglfgglfgglfgglfgglfgjlnL8H2jesL/cPj06U++HJ18v90kOT53xPtFqr9gw3j5v6dx/zlSc/\nhBI/hBI/hBI/hBI/hBI/hHLU1wNHtoyW+23LT5T7TYduL/eVv3n6nO8JuvHkh1Dih1Dih1Dih1Di\nh1Dih1Dih1DO+Xtg+0cfLfduv7I79OPVXd7hr+d4R9CdJz+EEj+EEj+EEj+EEj+EEj+EEj+Ecs7f\nBw+8+qFyH969v093Av/nyQ+hxA+hxA+hxA+hxA+hxA+hxA+hnPPP0uDoSOO2on2sj3cCveHJD6HE\nD6HED6HED6HED6HED6HED6Gc88/Ssbuua9w+u+L35bUHT7+9x3fDbPz3Y/+e87VnZoZ6eCfzkyc/\nhBI/hBI/hBI/hBI/hBI/hHLUx4I1dfN7yn3nu35UrBeV1z783Y+U+0jryXJfCDz5IZT4IZT4IZT4\nIZT4IZT4IZT4IZRzfuatbuf4J7edLvf1S5vP8re+fGN57ej4wXLvlOvC4MkPocQPocQPocQPocQP\nocQPocQPoZzzz9LKl6Ybt5emzvTxThaPgSX1j9+p7a+V+4F37yz3ibPLGrfD32j+U+ytVqs1NHmg\n3BcDT34IJX4IJX4IJX4IJX4IJX4IJX4I5Zx/li751VON22Pf2lBeu274RLkfueId5T517OVyv5Bm\nbtpY7ke3Nm+f3vBsee2Oy+pz/G52fGVL47bsd/vf1GsvBp78EEr8EEr8EEr8EEr8EEr8EMpRXx9s\nHT1a7sd3ryz3AyfX9PJ2euq+tT8t941Dc/8Re+aN5l+jbrVardv331Xu6x7/c+NWv3IGT34IJX4I\nJX4IJX4IJX4IJX4IJX4I5Zy/Bx78/sfL/ZVtT5T7N9/yXP0G3fYLqv4RmipO1J97o37lz41/qdzX\nfnVfuTvLr3nyQyjxQyjxQyjxQyjxQyjxQyjxQ6iBTqfTtzfb3B7r35vNI4NXri33Tb8+VO5fXnWk\nl7fTU+v33FnuQ89f3Lhd8Z29vb4dWq3WxMyugdl8nSc/hBI/hBI/hBI/hBI/hBI/hBI/hHLOD4uM\nc36gJH4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4I\nJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4IJX4I1deP6AbmD09+CCV+CCV+CCV+CCV+CCV+\nCCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CPU/x2Xv\nx7nqBBMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ec3dcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  1.00000000e+00   3.50560683e-12   1.00434594e-09   1.73949210e-14\n",
      "    8.60713218e-16   3.75027960e-12   9.13440157e-11   2.25712261e-11\n",
      "    1.23941948e-12   4.15561162e-11]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1274c8090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "Class probabilities =  [[  1.41643053e-09   7.71405238e-14   1.62943230e-15   5.57100261e-15\n",
      "    2.53674198e-13   1.26207560e-11   1.00000000e+00   4.33625261e-15\n",
      "    3.95802037e-11   7.02078399e-16]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhqECvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1277466d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Class probabilities =  [[  3.76756785e-12   1.12312442e-11   3.20851019e-11   2.01345451e-09\n",
      "    2.59802891e-05   6.02736749e-09   2.61297559e-12   4.99466495e-08\n",
      "    6.30753760e-09   9.99974012e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12778c250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Class probabilities =  [[  1.00000000e+00   1.98105139e-12   1.07032493e-12   2.90848210e-14\n",
      "    8.34232247e-15   6.83068185e-12   1.36369707e-08   4.16134821e-10\n",
      "    5.86183532e-12   1.50796278e-10]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print \"Label = \", label\n",
    "    print \"Class probabilities = \", y_probs.eval(feed_dict={\n",
    "        x: batch[0], y_: batch[1], keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, Dropout\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# channels = 1\n",
    "# rows = train_data.shape[1]\n",
    "# cols = train_data.shape[2]\n",
    "# if K.image_data_format() == \"channels_first\":\n",
    "#     train_data = train_data.reshape(train_data.shape[0],\n",
    "#                                     channels, rows, cols)\n",
    "#     test_data = test_data.reshape(test_data.shape[0], \n",
    "#                                   channels, rows, cols)\n",
    "#     input_shape = (channels, rows, cols)\n",
    "# else:\n",
    "#     train_data = train_data.reshape(train_data.shape[0],\n",
    "#                                     rows, cols, channels)\n",
    "#     test_data = test_data.reshape(test_data.shape[0],\n",
    "#                                   rows, cols, channels)\n",
    "#     input_shape = (rows, cols, channels)\n",
    "    \n",
    "# # Convert labels to one hot representation\n",
    "# train_labels = keras.utils.to_categorical(train_labels,\n",
    "#                                           num_classes)\n",
    "# test_labels = keras.utils.to_categorical(test_labels,\n",
    "#                                           num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Keras Implementation) Softmax Regression Model on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 805\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_53 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " 9568/10000 [===========================>..] - ETA: 0sTest loss: 0.300412044334\n",
      "Test accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"saved_models/\"\n",
    "model_name = \"softmax_regr_model.h5\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "lr = 0.5\n",
    "batch_size = 100\n",
    "epochs = 16\n",
    "seed = np.random.randint(1000)\n",
    "print(\"Seed: %d\" %seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "input_shape = (rows, cols, channels)\n",
    "inputs = Input(shape = input_shape)\n",
    "x = Flatten()(inputs)\n",
    "outputs = Dense(10, activation = 'softmax', \n",
    "                kernel_initializer = 'zeros')(x)\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = SGD(lr = 0.5),\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = filepath,\n",
    "                             verbose=1,\n",
    "                             save_best_only = True)\n",
    "\n",
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    model.train_on_batch(batch[0].reshape(100, rows, cols, 1),\n",
    "                         batch[1])\n",
    "    \n",
    "test_data = mnist.test.images.reshape(-1, rows, cols, 1)\n",
    "test_labels = mnist.test.labels\n",
    "score = model.evaluate(test_data, test_labels, verbose = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Keras Implementation) Softmax Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 911\n",
      "(50, 28, 28, 1) (10000, 28, 28, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 0, training accuracy: 0.04\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 1000, training accuracy: 0.9\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 2000, training accuracy: 0.96\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 3000, training accuracy: 1\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 4000, training accuracy: 0.92\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 5000, training accuracy: 0.94\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 6000, training accuracy: 0.96\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 7000, training accuracy: 0.98\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 8000, training accuracy: 0.98\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 9000, training accuracy: 0.96\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 10000, training accuracy: 0.98\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 11000, training accuracy: 0.98\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 12000, training accuracy: 1\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 13000, training accuracy: 1\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 14000, training accuracy: 1\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 15000, training accuracy: 0.96\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 16000, training accuracy: 0.98\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 17000, training accuracy: 1\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 18000, training accuracy: 1\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "Step 19000, training accuracy: 1\n",
      " 9952/10000 [============================>.] - ETA: 0sTest loss: 0.0719965533347\n",
      "Test accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"saved_models/\"\n",
    "model_name = \"softmax_mlp_model.h5\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "lr = 1e-4\n",
    "batch_size = 50\n",
    "epochs = 166\n",
    "seed = np.random.randint(1000)\n",
    "print(\"Seed: %d\" %seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "weight_init = keras.initializers.RandomNormal(stddev = 0.1,\n",
    "                                              seed = seed)\n",
    "bias_init = keras.initializers.Constant(value = 0.1)\n",
    "print(train_data.shape, test_data.shape)\n",
    "inputs = Input(shape = input_shape)\n",
    "x = Flatten()(inputs)\n",
    "x = Dense(512, activation = 'relu', \n",
    "          kernel_initializer = weight_init,\n",
    "          bias_initializer = bias_init)(x)\n",
    "outputs = Dense(num_classes, activation = 'softmax',\n",
    "          kernel_initializer = weight_init,\n",
    "          bias_initializer = bias_init)(x)\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr = lr),\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = filepath,\n",
    "                             verbose=1,\n",
    "                             save_best_only = True)\n",
    "\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    train_data = batch[0].reshape(batch_size, rows, cols, 1)\n",
    "    train_labels = batch[1]\n",
    "    if i % 1000 == 0:\n",
    "        _, train_accuracy = model.evaluate(train_data, train_labels)\n",
    "        print(\"\\nStep %d, training accuracy: %g\"%(i, train_accuracy))\n",
    "    model.train_on_batch(train_data, train_labels)\n",
    "\n",
    "test_data = mnist.test.images.reshape(-1, rows, cols, 1)\n",
    "test_labels = mnist.test.labels\n",
    "score = model.evaluate(test_data, test_labels, verbose = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Keras Implementation) Simple CNN: LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 124\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_66 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "50/50 [==============================] - 0s     \n",
      "\n",
      "Step 0, training accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"saved_models/\"\n",
    "model_name = \"simple_cnn_model.h5\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "lr = 1e-4\n",
    "batch_size = 50\n",
    "input_shape = (rows, cols, channels)\n",
    "\n",
    "seed = np.random.randint(1000)\n",
    "print(\"Seed: %d\" %seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "weight_init = keras.initializers.RandomNormal(stddev = 0.1,\n",
    "                                              seed = seed)\n",
    "bias_init = keras.initializers.Constant(value = 0.1)\n",
    "\n",
    "inputs = Input(shape = input_shape)\n",
    "x = Conv2D(32, kernel_size = 5, padding = 'same',\n",
    "           kernel_initializer = weight_init,\n",
    "           bias_initializer = bias_init)(inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2,\n",
    "                 padding='same')(x)\n",
    "x = Conv2D(64, kernel_size = 5, padding = 'same',\n",
    "           kernel_initializer = weight_init,\n",
    "           bias_initializer = bias_init)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2,\n",
    "                 padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu', \n",
    "          kernel_initializer = weight_init,\n",
    "          bias_initializer = bias_init)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(num_classes, activation = 'softmax',\n",
    "          kernel_initializer = weight_init,\n",
    "          bias_initializer = bias_init)(x)\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr = lr),\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = filepath,\n",
    "                             verbose=1,\n",
    "                             save_best_only = True)\n",
    "\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    train_data = batch[0].reshape(batch_size, rows, cols, 1)\n",
    "    train_labels = batch[1]\n",
    "    if i % 1000 == 0:\n",
    "        _, train_accuracy = model.evaluate(train_data, train_labels)\n",
    "        print(\"\\nStep %d, training accuracy: %g\"%(i, train_accuracy))\n",
    "    model.train_on_batch(train_data, train_labels)\n",
    "\n",
    "test_data = mnist.test.images.reshape(-1, rows, cols, 1)\n",
    "test_labels = mnist.test.labels\n",
    "score = model.evaluate(test_data, test_labels, verbose = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
